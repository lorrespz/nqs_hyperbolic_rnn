{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83eba79a",
   "metadata": {},
   "source": [
    "# 1D J1J2J3: (J2=0.5, J3=0.2) - 2nd set of experiments\n",
    "\n",
    "This notebook is part of the work arXiv:2505.22083 (https://arxiv.org/abs/2505.22083), \"Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz\". Code written by HLD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9abff75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 17:37:34.220168: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Norm clipping by value in the range [-2, 2] for hyperbolic networks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../utility')\n",
    "from j1j2j3_hyprnn_train_loop_grad_clipping import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fd866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_exact = -11.5287\n",
    "syssize = 30 #30 is divisible by both 2 and 3\n",
    "nssamples = 50\n",
    "J1 = 1.0\n",
    "J2 = 0.5\n",
    "J3 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f89e",
   "metadata": {},
   "source": [
    "# EuclGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6ddbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_eucl_wf at 0x19ef43b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 60\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "wf_egru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632c32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.49794, mean energy: 11.29978+0.37143j, varE: 1.40917\n",
      "step: 10, loss: -3.51608, mean energy: -1.16016+0.02446j, varE: 8.54640\n",
      "step: 20, loss: -3.68297, mean energy: -3.55704+0.13036j, varE: 6.26923\n",
      "step: 30, loss: -3.20737, mean energy: -5.00485+0.19399j, varE: 3.68202\n",
      "step: 40, loss: -7.49615, mean energy: -6.45960-0.13954j, varE: 4.96866\n",
      "Best model saved at epoch 50 with best E=-8.42214-0.14513j, varE=1.92175\n",
      "step: 50, loss: -1.40786, mean energy: -8.42214-0.14513j, varE: 1.92175\n",
      "step: 60, loss: 1.89986, mean energy: -7.94941+0.34825j, varE: 2.71834\n",
      "Best model saved at epoch 69 with best E=-8.84826+0.14143j, varE=1.69624\n",
      "Best model saved at epoch 70 with best E=-9.01429-0.04766j, varE=1.96896\n",
      "step: 70, loss: 0.50349, mean energy: -9.01429-0.04766j, varE: 1.96896\n",
      "Best model saved at epoch 80 with best E=-9.40039+0.06367j, varE=1.73536\n",
      "step: 80, loss: 1.92274, mean energy: -9.40039+0.06367j, varE: 1.73536\n",
      "Best model saved at epoch 85 with best E=-9.40264-0.04374j, varE=1.56997\n",
      "Best model saved at epoch 87 with best E=-9.42271-0.17432j, varE=1.50133\n",
      "Best model saved at epoch 88 with best E=-9.66796-0.19733j, varE=1.76410\n",
      "step: 90, loss: -5.44909, mean energy: -9.31665-0.17392j, varE: 2.63028\n",
      "step: 100, loss: 4.41608, mean energy: -8.97789+0.11270j, varE: 2.62588\n",
      "Best model saved at epoch 102 with best E=-9.76456+0.04946j, varE=1.69599\n",
      "Best model saved at epoch 104 with best E=-9.91954-0.04729j, varE=1.55839\n",
      "step: 110, loss: 1.90388, mean energy: -9.20932+0.08492j, varE: 2.43433\n",
      "Best model saved at epoch 116 with best E=-9.97664+0.08466j, varE=1.69748\n",
      "Best model saved at epoch 118 with best E=-10.22097-0.15806j, varE=1.04557\n",
      "step: 120, loss: -2.51931, mean energy: -9.96998+0.02209j, varE: 1.60814\n",
      "step: 130, loss: -0.98347, mean energy: -8.93242-0.05886j, varE: 2.29198\n",
      "Best model saved at epoch 132 with best E=-10.28063-0.01378j, varE=1.61086\n",
      "step: 140, loss: -0.76872, mean energy: -8.90820+0.01429j, varE: 1.75719\n",
      "step: 150, loss: -1.65930, mean energy: -9.73807-0.03136j, varE: 1.57856\n",
      "step: 160, loss: -2.86017, mean energy: -9.94977+0.00082j, varE: 2.05881\n",
      "step: 170, loss: -1.66465, mean energy: -10.00374+0.02044j, varE: 0.92406\n",
      "Best model saved at epoch 176 with best E=-10.30153-0.11704j, varE=1.48781\n",
      "Best model saved at epoch 178 with best E=-10.30773-0.15639j, varE=0.78613\n",
      "step: 180, loss: -2.18925, mean energy: -10.18229-0.14447j, varE: 1.66898\n",
      "Best model saved at epoch 182 with best E=-10.46385-0.09828j, varE=1.53928\n",
      "step: 190, loss: 0.11630, mean energy: -9.96234-0.06957j, varE: 1.49451\n",
      "Best model saved at epoch 196 with best E=-10.56643-0.10645j, varE=1.11858\n",
      "step: 200, loss: -1.91611, mean energy: -10.28903-0.19435j, varE: 1.06827\n",
      "step: 210, loss: -4.99702, mean energy: -10.34458-0.00451j, varE: 1.60601\n",
      "step: 220, loss: 6.03685, mean energy: -10.56291-0.05218j, varE: 1.38272\n",
      "Best model saved at epoch 221 with best E=-10.70339-0.01963j, varE=1.10048\n",
      "step: 230, loss: -4.85110, mean energy: -10.42583-0.18577j, varE: 1.69938\n",
      "Best model saved at epoch 233 with best E=-10.77690-0.00683j, varE=1.07767\n",
      "Best model saved at epoch 236 with best E=-10.88924+0.02615j, varE=1.51815\n",
      "step: 240, loss: -1.96411, mean energy: -10.79381-0.09762j, varE: 1.14873\n",
      "Best model saved at epoch 247 with best E=-10.93115-0.20581j, varE=1.02579\n",
      "step: 250, loss: -4.71397, mean energy: -10.79317-0.18577j, varE: 1.03202\n",
      "Best model saved at epoch 253 with best E=-11.06823-0.00985j, varE=0.87022\n",
      "Best model saved at epoch 256 with best E=-11.08785-0.04885j, varE=0.30434\n",
      "step: 260, loss: 3.06706, mean energy: -11.02727-0.13809j, varE: 0.63848\n",
      "Best model saved at epoch 261 with best E=-11.10349-0.01389j, varE=0.52752\n",
      "Best model saved at epoch 262 with best E=-11.27316-0.08421j, varE=0.45792\n",
      "step: 270, loss: 1.19643, mean energy: -11.22910-0.04184j, varE: 0.21848\n",
      "Best model saved at epoch 272 with best E=-11.32454+0.07546j, varE=0.54006\n",
      "step: 280, loss: -0.09423, mean energy: -11.04778-0.00513j, varE: 0.22202\n",
      "Best model saved at epoch 287 with best E=-11.32852-0.00064j, varE=0.20152\n",
      "step: 290, loss: 0.35218, mean energy: -11.31168-0.02356j, varE: 0.47862\n",
      "Best model saved at epoch 295 with best E=-11.36587+0.06405j, varE=0.27556\n",
      "step: 300, loss: -1.79060, mean energy: -11.10251+0.00664j, varE: 0.32815\n",
      "step: 310, loss: 0.49004, mean energy: -11.01993-0.02724j, varE: 0.99249\n",
      "step: 320, loss: 0.22801, mean energy: -11.14840-0.01039j, varE: 0.49831\n",
      "step: 330, loss: -2.13370, mean energy: -11.28612-0.07621j, varE: 0.24730\n",
      "step: 340, loss: 0.89883, mean energy: -11.32986-0.04177j, varE: 0.10215\n",
      "step: 350, loss: 0.90343, mean energy: -11.28756-0.02088j, varE: 0.21647\n",
      "Best model saved at epoch 355 with best E=-11.36952+0.04553j, varE=0.20141\n",
      "step: 360, loss: -0.02373, mean energy: -11.25057-0.04167j, varE: 1.12588\n",
      "Best model saved at epoch 364 with best E=-11.40407-0.01055j, varE=0.14394\n",
      "step: 370, loss: -1.60388, mean energy: -11.22172+0.01744j, varE: 0.22670\n",
      "Best model saved at epoch 373 with best E=-11.41122-0.02727j, varE=0.17131\n",
      "step: 380, loss: -0.84490, mean energy: -11.26892+0.01535j, varE: 0.21433\n",
      "Best model saved at epoch 389 with best E=-11.47059+0.03330j, varE=0.11308\n",
      "step: 390, loss: 1.89103, mean energy: -11.24287+0.04694j, varE: 0.37025\n",
      "step: 400, loss: 0.92618, mean energy: -11.34242-0.00073j, varE: 0.07229\n",
      "step: 410, loss: -0.68733, mean energy: -11.35546-0.05074j, varE: 0.07443\n",
      "step: 420, loss: 0.41206, mean energy: -11.22797+0.02799j, varE: 0.54230\n",
      "step: 430, loss: -0.63124, mean energy: -11.37903+0.04663j, varE: 0.07772\n",
      "step: 440, loss: 0.00995, mean energy: -11.32902-0.01423j, varE: 0.09537\n",
      "step: 450, loss: 0.42558, mean energy: -11.31219-0.02592j, varE: 0.13520\n",
      "step: 460, loss: -0.52220, mean energy: -11.43323+0.10169j, varE: 0.07466\n",
      "step: 470, loss: -0.30028, mean energy: -11.35925+0.00109j, varE: 0.18823\n",
      "step: 480, loss: 0.60057, mean energy: -11.32147-0.03466j, varE: 0.47632\n",
      "step: 490, loss: -0.30054, mean energy: -11.35581-0.00899j, varE: 0.03934\n",
      "step: 500, loss: -0.83580, mean energy: -11.37828+0.01774j, varE: 0.07513\n"
     ]
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 60\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "nsteps = 551\n",
    "start = time.time()\n",
    "\n",
    "mE, vE = run_J1J2J3(wf=wf_egru, numsteps=nsteps, systemsize=syssize, var_tol=2.0, J1_  = J1, \n",
    "                   J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                  numsamples = nssamples, learningrate = 1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587abf4",
   "metadata": {},
   "source": [
    "# HypGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54aa40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Norm clipping by value in the range [(-3.0, 3.0)] for hyperbolic networks\n",
      "GRADIENT CLIPPING BY VALUE IN THE RANGE [-3,3]\n",
      "step: 0, loss: -1.53725, mean energy: 11.52415-0.00719j, varE: 1.48318\n",
      "step: 10, loss: 1.67056, mean energy: -1.00021+0.33911j, varE: 7.47834\n",
      "step: 20, loss: 1.64580, mean energy: -2.05559+0.09726j, varE: 5.46968\n",
      "step: 30, loss: 4.84080, mean energy: -4.23605-0.27753j, varE: 5.05623\n",
      "step: 40, loss: 0.95148, mean energy: -5.43992+0.35796j, varE: 5.26424\n",
      "step: 50, loss: 0.44630, mean energy: -7.79744+0.10236j, varE: 3.47661\n",
      "step: 60, loss: -3.15452, mean energy: -8.49872-0.06829j, varE: 4.30941\n",
      "Best model saved at epoch 61 with best E=-8.82396+0.09579j, varE=2.12242\n",
      "Best model saved at epoch 64 with best E=-8.94994+0.08004j, varE=2.18512\n",
      "Best model saved at epoch 67 with best E=-9.13867-0.18058j, varE=2.17446\n",
      "step: 70, loss: 2.48067, mean energy: -9.08606-0.19984j, varE: 3.51187\n",
      "Best model saved at epoch 72 with best E=-9.47132-0.00204j, varE=2.04923\n",
      "Best model saved at epoch 74 with best E=-9.57800-0.10812j, varE=1.66810\n",
      "Best model saved at epoch 75 with best E=-9.68310-0.21563j, varE=1.86532\n",
      "Best model saved at epoch 79 with best E=-9.78925+0.02359j, varE=1.31369\n",
      "step: 80, loss: -6.02042, mean energy: -9.39470-0.00499j, varE: 3.77048\n",
      "Best model saved at epoch 84 with best E=-10.10776+0.22239j, varE=1.69253\n",
      "step: 90, loss: -7.06590, mean energy: -9.59484+0.19223j, varE: 3.22525\n",
      "step: 100, loss: 4.90365, mean energy: -9.93841-0.01179j, varE: 1.96201\n",
      "step: 110, loss: -5.23402, mean energy: -9.98502+0.05949j, varE: 1.50279\n",
      "step: 120, loss: 1.89672, mean energy: -9.86350-0.07499j, varE: 1.18408\n",
      "Best model saved at epoch 126 with best E=-10.13395-0.00072j, varE=1.20440\n",
      "Best model saved at epoch 127 with best E=-10.23242+0.00838j, varE=0.72148\n",
      "Best model saved at epoch 129 with best E=-10.26320-0.14032j, varE=1.18629\n",
      "step: 130, loss: -2.35822, mean energy: -10.23390-0.05711j, varE: 1.25003\n",
      "step: 140, loss: -4.56110, mean energy: -9.86243-0.16176j, varE: 2.70940\n",
      "Best model saved at epoch 143 with best E=-10.40426+0.01864j, varE=1.40612\n",
      "step: 150, loss: 1.33463, mean energy: -9.96486+0.18108j, varE: 3.29051\n",
      "step: 160, loss: 1.78376, mean energy: -10.18279-0.06612j, varE: 3.91285\n",
      "step: 170, loss: 5.74532, mean energy: -9.46550-0.03047j, varE: 3.23285\n",
      "step: 180, loss: 1.73901, mean energy: -10.21053+0.01593j, varE: 2.57720\n",
      "step: 190, loss: -0.49921, mean energy: -10.33672-0.06549j, varE: 0.77560\n",
      "Best model saved at epoch 191 with best E=-10.41855+0.09044j, varE=0.88851\n",
      "Best model saved at epoch 192 with best E=-10.46971+0.03304j, varE=1.29085\n",
      "Best model saved at epoch 193 with best E=-10.62169-0.07494j, varE=0.87052\n",
      "Best model saved at epoch 196 with best E=-10.82194-0.08792j, varE=1.04125\n",
      "Best model saved at epoch 200 with best E=-10.84054-0.12802j, varE=0.63331\n",
      "step: 200, loss: -1.53001, mean energy: -10.84054-0.12802j, varE: 0.63331\n",
      "step: 210, loss: -2.97228, mean energy: -10.68791+0.17068j, varE: 1.40849\n",
      "Best model saved at epoch 213 with best E=-10.85569-0.10852j, varE=0.73327\n",
      "Best model saved at epoch 216 with best E=-10.88517+0.08267j, varE=0.54979\n",
      "step: 220, loss: -1.51284, mean energy: -10.67326+0.19088j, varE: 1.28035\n",
      "step: 230, loss: -1.55186, mean energy: -10.03403+0.16734j, varE: 5.03565\n",
      "step: 240, loss: -3.45858, mean energy: -10.33345+0.10024j, varE: 1.38006\n",
      "step: 250, loss: -0.40311, mean energy: -10.60562-0.08571j, varE: 1.33186\n",
      "step: 260, loss: -2.04133, mean energy: -10.69948+0.09412j, varE: 0.82103\n",
      "step: 270, loss: 1.68716, mean energy: -10.77164+0.11294j, varE: 0.65877\n",
      "Best model saved at epoch 275 with best E=-10.95546+0.10433j, varE=0.76568\n",
      "Best model saved at epoch 279 with best E=-11.13033+0.04094j, varE=0.64112\n",
      "step: 280, loss: -0.43446, mean energy: -10.96805-0.04723j, varE: 0.90208\n",
      "step: 290, loss: -0.24877, mean energy: -11.03069-0.02661j, varE: 0.29121\n",
      "Best model saved at epoch 293 with best E=-11.13509-0.10593j, varE=0.77690\n",
      "step: 300, loss: -0.19559, mean energy: -11.05419-0.02726j, varE: 0.76383\n",
      "Best model saved at epoch 301 with best E=-11.27027+0.05440j, varE=0.32405\n",
      "step: 310, loss: -0.46445, mean energy: -11.14450+0.07422j, varE: 0.71177\n",
      "step: 320, loss: -0.99722, mean energy: -11.00943-0.02023j, varE: 0.78106\n",
      "step: 330, loss: -0.12756, mean energy: -11.19346+0.00128j, varE: 0.42046\n",
      "step: 340, loss: 3.37756, mean energy: -10.17069+0.03606j, varE: 1.63647\n",
      "step: 350, loss: -5.56135, mean energy: -10.09938+0.24123j, varE: 2.19256\n",
      "step: 360, loss: -1.85645, mean energy: -10.81816+0.03028j, varE: 1.11156\n",
      "step: 370, loss: -1.55046, mean energy: -10.80038-0.09346j, varE: 0.96647\n",
      "step: 380, loss: 0.92194, mean energy: -10.93871-0.10024j, varE: 0.71680\n",
      "Best model saved at epoch 390 with best E=-11.31907-0.04487j, varE=0.44938\n",
      "step: 390, loss: 0.19580, mean energy: -11.31907-0.04487j, varE: 0.44938\n",
      "step: 400, loss: 2.10976, mean energy: -11.10915+0.02833j, varE: 0.60325\n",
      "step: 410, loss: -1.56867, mean energy: -11.19981+0.00111j, varE: 0.60410\n",
      "Best model saved at epoch 413 with best E=-11.32615+0.02167j, varE=0.27818\n",
      "Best model saved at epoch 420 with best E=-11.34678-0.07091j, varE=0.19169\n",
      "step: 420, loss: 1.32802, mean energy: -11.34678-0.07091j, varE: 0.19169\n",
      "Best model saved at epoch 428 with best E=-11.38744-0.00807j, varE=0.17698\n",
      "Best model saved at epoch 430 with best E=-11.39217-0.03299j, varE=0.25394\n",
      "step: 430, loss: 1.32751, mean energy: -11.39217-0.03299j, varE: 0.25394\n",
      "step: 440, loss: -0.40984, mean energy: -11.32087+0.01907j, varE: 0.08671\n",
      "step: 450, loss: -0.99861, mean energy: -11.28716+0.03844j, varE: 0.25565\n",
      "Best model saved at epoch 452 with best E=-11.39295-0.04090j, varE=0.15225\n",
      "Best model saved at epoch 454 with best E=-11.42088+0.00645j, varE=0.11110\n",
      "step: 460, loss: -0.37252, mean energy: -11.36331-0.00909j, varE: 0.09716\n",
      "step: 470, loss: -1.86248, mean energy: -11.16388+0.01673j, varE: 0.44988\n",
      "Best model saved at epoch 478 with best E=-11.42531-0.02614j, varE=0.27877\n",
      "step: 480, loss: -1.23615, mean energy: -11.21119-0.02080j, varE: 0.45693\n",
      "Best model saved at epoch 484 with best E=-11.49844+0.11653j, varE=1.49092\n",
      "step: 490, loss: -0.83187, mean energy: -11.30665+0.05114j, varE: 0.42770\n",
      "step: 500, loss: 0.11364, mean energy: -11.29965-0.01607j, varE: 0.34208\n",
      "Total time taken: 16.339\n"
     ]
    }
   ],
   "source": [
    "#WITH GRADIENT CLIPPING BY NORM VALUE [-3.,3.]\n",
    "from j1j2j3_hyprnn_train_loop_grad_clipping_v3 import *\n",
    "print('GRADIENT CLIPPING BY VALUE IN THE RANGE [-3,3]')\n",
    "cell_type = 'HypGRU'\n",
    "hidden_units = 57\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "nsteps=501\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.55,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../v-results-gc-2')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b32fdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT CLIPPING BY VALUE IN THE RANGE [-2,2]\n",
      "step: 0, loss: -1.53725, mean energy: 11.52415-0.00719j, varE: 1.48318\n",
      "step: 10, loss: 1.81928, mean energy: -0.80784+0.29434j, varE: 7.62298\n",
      "step: 20, loss: -0.41074, mean energy: -2.91785-0.15689j, varE: 4.80973\n",
      "step: 30, loss: 7.11909, mean energy: -4.30916-0.04540j, varE: 5.64757\n",
      "step: 40, loss: 4.01813, mean energy: -5.89479+0.01191j, varE: 3.88011\n",
      "step: 50, loss: -1.36086, mean energy: -7.06138-0.17533j, varE: 4.30842\n",
      "step: 60, loss: -2.93062, mean energy: -8.36341+0.02510j, varE: 3.68126\n",
      "Best model saved at epoch 65 with best E=-8.28864+0.14392j, varE=2.50182\n",
      "Best model saved at epoch 67 with best E=-8.74071+0.08000j, varE=1.73014\n",
      "step: 70, loss: 0.69382, mean energy: -8.48460+0.21320j, varE: 2.31904\n",
      "Best model saved at epoch 77 with best E=-9.29639-0.03022j, varE=2.06263\n",
      "Best model saved at epoch 80 with best E=-9.32774-0.15120j, varE=2.33819\n",
      "step: 80, loss: -2.20685, mean energy: -9.32774-0.15120j, varE: 2.33819\n",
      "Best model saved at epoch 84 with best E=-10.07217-0.12658j, varE=1.67776\n",
      "step: 90, loss: -4.04180, mean energy: -8.76655-0.43917j, varE: 3.77420\n",
      "step: 100, loss: -1.72986, mean energy: -9.05506+0.09691j, varE: 4.09349\n",
      "step: 110, loss: 0.12785, mean energy: -9.95578-0.08194j, varE: 2.98209\n",
      "Best model saved at epoch 119 with best E=-10.14810+0.11206j, varE=1.73580\n",
      "step: 120, loss: -2.11066, mean energy: -9.95698+0.14433j, varE: 2.29908\n",
      "Best model saved at epoch 121 with best E=-10.45322-0.04805j, varE=1.15632\n",
      "step: 130, loss: -2.60291, mean energy: -10.39170-0.26704j, varE: 0.96065\n",
      "Best model saved at epoch 132 with best E=-10.55062+0.15608j, varE=1.18013\n",
      "Best model saved at epoch 133 with best E=-10.58906-0.12435j, varE=1.47369\n",
      "Best model saved at epoch 135 with best E=-10.63197-0.06282j, varE=1.49428\n",
      "Best model saved at epoch 137 with best E=-10.80727-0.11275j, varE=0.95384\n",
      "step: 140, loss: 1.35676, mean energy: -10.60856-0.07566j, varE: 1.14819\n",
      "step: 150, loss: -3.87949, mean energy: -10.38378-0.05583j, varE: 2.17805\n",
      "Best model saved at epoch 159 with best E=-10.86989+0.02861j, varE=1.06507\n",
      "step: 160, loss: -1.44556, mean energy: -10.81724+0.07495j, varE: 0.75001\n",
      "step: 170, loss: -0.79620, mean energy: -10.59162-0.08534j, varE: 0.87916\n",
      "Best model saved at epoch 180 with best E=-10.95245+0.06670j, varE=1.14870\n",
      "step: 180, loss: 0.35374, mean energy: -10.95245+0.06670j, varE: 1.14870\n",
      "step: 190, loss: -1.00990, mean energy: -10.78285-0.14974j, varE: 0.88800\n",
      "step: 200, loss: 1.22723, mean energy: -10.68896+0.05023j, varE: 1.32939\n",
      "Best model saved at epoch 203 with best E=-10.95399-0.02556j, varE=0.76431\n",
      "Best model saved at epoch 206 with best E=-11.08001-0.09889j, varE=1.07468\n",
      "step: 210, loss: -2.26212, mean energy: -10.95824+0.01693j, varE: 0.57003\n",
      "step: 220, loss: 1.41858, mean energy: -10.94097+0.06188j, varE: 1.05065\n",
      "Best model saved at epoch 221 with best E=-11.14307-0.04152j, varE=0.48461\n",
      "step: 230, loss: -0.19037, mean energy: -11.11144+0.09413j, varE: 0.61549\n",
      "Best model saved at epoch 235 with best E=-11.15000-0.03508j, varE=0.40186\n",
      "Best model saved at epoch 239 with best E=-11.28511+0.00293j, varE=0.62406\n",
      "step: 240, loss: -1.57780, mean energy: -11.09920+0.03180j, varE: 0.77998\n",
      "step: 250, loss: -0.31962, mean energy: -11.17797+0.01683j, varE: 0.29101\n",
      "step: 260, loss: -1.52398, mean energy: -11.18947+0.07218j, varE: 0.24682\n",
      "Best model saved at epoch 270 with best E=-11.33647-0.00262j, varE=0.14653\n",
      "step: 270, loss: -0.33593, mean energy: -11.33647-0.00262j, varE: 0.14653\n",
      "step: 280, loss: -1.12688, mean energy: -11.12280+0.06019j, varE: 0.36232\n",
      "step: 290, loss: -0.71277, mean energy: -11.23149+0.05111j, varE: 0.20034\n",
      "step: 300, loss: 0.50591, mean energy: -11.15786-0.03228j, varE: 0.42583\n",
      "step: 310, loss: -1.04928, mean energy: -11.28347+0.05202j, varE: 0.35133\n",
      "step: 320, loss: -0.99684, mean energy: -11.28643-0.01455j, varE: 0.17787\n",
      "step: 330, loss: -0.19744, mean energy: -11.27577-0.02450j, varE: 0.07201\n",
      "step: 340, loss: 0.50337, mean energy: -11.27450+0.01367j, varE: 0.08670\n",
      "Best model saved at epoch 345 with best E=-11.37030-0.03952j, varE=0.19909\n",
      "step: 350, loss: -0.88332, mean energy: -11.23900-0.04002j, varE: 0.28775\n",
      "step: 360, loss: -0.45813, mean energy: -11.31355-0.01077j, varE: 0.07939\n",
      "step: 370, loss: -0.33250, mean energy: -11.29316+0.00549j, varE: 0.05850\n",
      "Best model saved at epoch 375 with best E=-11.37048-0.02736j, varE=0.10698\n",
      "step: 380, loss: -0.17339, mean energy: -11.34165-0.00479j, varE: 0.05956\n",
      "Best model saved at epoch 390 with best E=-11.47182+0.00834j, varE=1.53293\n",
      "step: 390, loss: 0.56643, mean energy: -11.47182+0.00834j, varE: 1.53293\n",
      "step: 400, loss: 0.27118, mean energy: -11.22929+0.04683j, varE: 0.33235\n",
      "step: 410, loss: 0.06550, mean energy: -11.29745+0.01112j, varE: 0.07481\n",
      "step: 420, loss: -0.58060, mean energy: -11.30162+0.01208j, varE: 0.08564\n",
      "step: 430, loss: -0.02906, mean energy: -11.31291-0.00003j, varE: 0.08823\n",
      "step: 440, loss: 2.24229, mean energy: -11.27843-0.00307j, varE: 0.30977\n",
      "step: 450, loss: -0.60305, mean energy: -11.37964-0.06783j, varE: 0.24391\n",
      "step: 460, loss: 0.60094, mean energy: -11.32268+0.03026j, varE: 0.06544\n",
      "step: 470, loss: -1.06798, mean energy: -11.30799-0.04618j, varE: 0.08292\n",
      "step: 480, loss: 0.05529, mean energy: -11.27097+0.01750j, varE: 0.21078\n",
      "step: 490, loss: -1.29862, mean energy: -11.26952+0.01021j, varE: 0.09198\n",
      "step: 500, loss: 1.54268, mean energy: -11.26956+0.02559j, varE: 0.18610\n",
      "Total time taken: 25.327\n"
     ]
    }
   ],
   "source": [
    "#WITH GRADIENT CLIPPING BY NORM VALUE [-2.,2.]\n",
    "print('GRADIENT CLIPPING BY VALUE IN THE RANGE [-2,2]')\n",
    "cell_type = 'HypGRU'\n",
    "hidden_units = 57\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "nsteps=501\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.55,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../v-results-gc')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5590cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.53725, mean energy: 11.52415-0.00719j, varE: 1.48318\n",
      "step: 10, loss: 1.01637, mean energy: -0.77162+0.34364j, varE: 7.12435\n",
      "step: 20, loss: -0.51485, mean energy: -2.99790+0.31205j, varE: 5.60159\n",
      "step: 30, loss: 1.83395, mean energy: -4.76198+0.01415j, varE: 4.28949\n",
      "step: 40, loss: -6.14925, mean energy: -6.42691-0.04555j, varE: 4.42178\n",
      "step: 50, loss: 5.39790, mean energy: -7.41833-0.22159j, varE: 3.31706\n",
      "Best model saved at epoch 58 with best E=-8.78309-0.01036j, varE=2.50604\n",
      "Best model saved at epoch 59 with best E=-8.82767+0.09205j, varE=2.45486\n",
      "Best model saved at epoch 60 with best E=-8.97324+0.16402j, varE=2.42281\n",
      "step: 60, loss: -4.20612, mean energy: -8.97324+0.16402j, varE: 2.42281\n",
      "Best model saved at epoch 62 with best E=-9.18459-0.13820j, varE=2.00130\n",
      "Best model saved at epoch 64 with best E=-9.34120+0.08832j, varE=2.42309\n",
      "Best model saved at epoch 65 with best E=-9.42021+0.15222j, varE=2.33523\n",
      "Best model saved at epoch 68 with best E=-9.59945-0.18602j, varE=1.67211\n",
      "step: 70, loss: -4.78103, mean energy: -9.49499+0.07739j, varE: 2.40563\n",
      "Best model saved at epoch 74 with best E=-9.61921-0.05085j, varE=2.12969\n",
      "Best model saved at epoch 78 with best E=-9.92015-0.15122j, varE=2.47921\n",
      "step: 80, loss: 1.06465, mean energy: -9.76542-0.11519j, varE: 1.02143\n",
      "step: 90, loss: -5.89027, mean energy: -9.79865+0.04578j, varE: 1.99348\n",
      "step: 100, loss: -1.37616, mean energy: -9.63404-0.17361j, varE: 1.08742\n",
      "Best model saved at epoch 105 with best E=-9.93920-0.01320j, varE=2.28927\n",
      "step: 110, loss: -0.19086, mean energy: -9.91143+0.02027j, varE: 1.50827\n",
      "Best model saved at epoch 111 with best E=-10.03922-0.02853j, varE=1.13297\n",
      "step: 120, loss: 2.41746, mean energy: -9.88913-0.23163j, varE: 1.75240\n",
      "Best model saved at epoch 123 with best E=-10.16377-0.16583j, varE=0.89218\n",
      "step: 130, loss: -2.01054, mean energy: -9.25491-0.05167j, varE: 5.09904\n",
      "step: 140, loss: -0.24516, mean energy: -9.74159+0.28851j, varE: 3.04198\n",
      "Best model saved at epoch 141 with best E=-10.20457-0.20123j, varE=1.32468\n",
      "Best model saved at epoch 149 with best E=-10.26136-0.06234j, varE=1.53410\n",
      "Best model saved at epoch 150 with best E=-10.72993-0.05903j, varE=1.06619\n",
      "step: 150, loss: -0.02644, mean energy: -10.72993-0.05903j, varE: 1.06619\n",
      "step: 160, loss: -0.21070, mean energy: -10.51669-0.02259j, varE: 1.26357\n",
      "step: 170, loss: 0.26205, mean energy: -10.55280-0.00668j, varE: 1.53954\n",
      "step: 180, loss: 3.51701, mean energy: -10.41685-0.03779j, varE: 0.54365\n",
      "step: 190, loss: 3.01013, mean energy: -9.50283-0.22310j, varE: 2.47977\n",
      "step: 200, loss: -1.83189, mean energy: -9.89515+0.10035j, varE: 1.96089\n",
      "step: 210, loss: -2.20312, mean energy: -10.14105-0.13535j, varE: 1.44092\n",
      "step: 220, loss: -1.79559, mean energy: -10.24294-0.01008j, varE: 1.74156\n",
      "Best model saved at epoch 222 with best E=-10.74253-0.02209j, varE=2.06733\n",
      "Best model saved at epoch 228 with best E=-10.76746-0.02913j, varE=1.01783\n",
      "Best model saved at epoch 230 with best E=-10.93909-0.13208j, varE=1.47058\n",
      "step: 230, loss: 0.61134, mean energy: -10.93909-0.13208j, varE: 1.47058\n",
      "step: 240, loss: 11.96978, mean energy: -8.48813-0.37682j, varE: 7.70512\n",
      "step: 250, loss: 3.79925, mean energy: -9.40216-0.13534j, varE: 2.27894\n",
      "step: 260, loss: -0.55141, mean energy: -7.09154-0.12537j, varE: 3.90725\n",
      "step: 270, loss: -1.93268, mean energy: -6.92150-0.17505j, varE: 7.95856\n",
      "step: 280, loss: -2.23045, mean energy: -7.98043-0.12839j, varE: 3.45321\n",
      "step: 290, loss: -4.50639, mean energy: -8.37310-0.01657j, varE: 2.06874\n",
      "step: 300, loss: -2.35101, mean energy: -9.32352+0.00667j, varE: 2.78938\n",
      "step: 310, loss: 0.52940, mean energy: -9.55641-0.07335j, varE: 2.17512\n",
      "step: 320, loss: 0.12960, mean energy: -10.02391-0.09690j, varE: 2.40583\n",
      "step: 330, loss: -0.10445, mean energy: -10.11493-0.13100j, varE: 0.59608\n",
      "step: 340, loss: 0.98715, mean energy: -10.43893-0.01835j, varE: 1.42193\n",
      "step: 350, loss: -1.06793, mean energy: -10.37831+0.02744j, varE: 1.40880\n",
      "step: 360, loss: 0.90689, mean energy: -10.40113+0.06695j, varE: 1.07914\n",
      "step: 370, loss: -4.17535, mean energy: -10.02160-0.06071j, varE: 2.10736\n",
      "step: 380, loss: -4.76493, mean energy: -10.51348+0.08359j, varE: 1.60304\n",
      "step: 390, loss: -3.42735, mean energy: -10.44969+0.08750j, varE: 2.66347\n",
      "step: 400, loss: 0.28697, mean energy: -10.66079-0.03992j, varE: 1.02425\n",
      "step: 410, loss: -1.12995, mean energy: -10.72997-0.14698j, varE: 0.46753\n",
      "step: 420, loss: -2.69299, mean energy: -10.68421+0.06532j, varE: 1.02195\n",
      "Best model saved at epoch 421 with best E=-11.06896-0.03916j, varE=0.35862\n",
      "step: 430, loss: 9.14948, mean energy: -10.83609-0.19670j, varE: 3.09907\n",
      "step: 440, loss: 2.83030, mean energy: -9.98373+0.10452j, varE: 2.60956\n",
      "step: 450, loss: 1.30438, mean energy: -10.79265-0.07941j, varE: 1.08221\n",
      "step: 460, loss: 2.12258, mean energy: -10.56653-0.13614j, varE: 1.47859\n",
      "step: 470, loss: -4.28688, mean energy: -10.71939+0.04018j, varE: 1.24659\n",
      "Best model saved at epoch 472 with best E=-11.09542-0.00701j, varE=0.33049\n",
      "Best model saved at epoch 473 with best E=-11.13284-0.00256j, varE=0.25816\n",
      "Best model saved at epoch 477 with best E=-11.16050-0.00459j, varE=0.86097\n",
      "Best model saved at epoch 478 with best E=-11.21474+0.03300j, varE=0.55609\n",
      "step: 480, loss: -1.82894, mean energy: -10.99518+0.05010j, varE: 0.62537\n",
      "Best model saved at epoch 488 with best E=-11.24194-0.02158j, varE=0.22560\n",
      "step: 490, loss: -0.91768, mean energy: -11.05381+0.06361j, varE: 0.30310\n",
      "Best model saved at epoch 494 with best E=-11.29300+0.00333j, varE=0.37287\n",
      "step: 500, loss: 1.85349, mean energy: -11.22211+0.01111j, varE: 0.44298\n",
      "Total time taken: 16.375\n"
     ]
    }
   ],
   "source": [
    "#WITH GRADIENT CLIPPING BY NORM VALUE [-1.,1.]\n",
    "cell_type = 'HypGRU'\n",
    "hidden_units = 57\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "nsteps=501\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.55,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../v-results-gc')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bd1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.53725, mean energy: 11.52415-0.00719j, varE: 1.48318\n",
      "step: 10, loss: -0.06060, mean energy: -0.73598+0.21279j, varE: 8.52583\n",
      "step: 20, loss: 3.58000, mean energy: -2.54576+0.03392j, varE: 6.39923\n",
      "step: 30, loss: -2.26369, mean energy: -5.11180-0.21194j, varE: 4.70692\n",
      "step: 40, loss: -4.99415, mean energy: -6.65871-0.05175j, varE: 4.42478\n",
      "step: 50, loss: 2.27335, mean energy: -7.88731-0.20993j, varE: 3.59857\n",
      "Best model saved at epoch 52 with best E=-8.42810-0.03112j, varE=2.22999\n",
      "Best model saved at epoch 55 with best E=-8.54184-0.15340j, varE=2.54051\n",
      "Best model saved at epoch 60 with best E=-9.16329+0.07193j, varE=1.87824\n",
      "step: 60, loss: -2.48755, mean energy: -9.16329+0.07193j, varE: 1.87824\n",
      "Best model saved at epoch 62 with best E=-9.26904-0.04750j, varE=2.39053\n",
      "Best model saved at epoch 67 with best E=-9.44151-0.03871j, varE=2.32227\n",
      "Best model saved at epoch 68 with best E=-9.86594-0.15083j, varE=1.19312\n",
      "step: 70, loss: -2.30797, mean energy: -9.76865+0.07089j, varE: 2.55179\n",
      "step: 80, loss: -1.75036, mean energy: -9.34098-0.11800j, varE: 1.63284\n",
      "Best model saved at epoch 87 with best E=-9.89533-0.02321j, varE=1.00647\n",
      "step: 90, loss: -1.82702, mean energy: -9.53723-0.13498j, varE: 4.12660\n",
      "step: 100, loss: -5.94459, mean energy: -9.47133-0.00580j, varE: 2.58655\n",
      "Best model saved at epoch 109 with best E=-9.92978+0.00040j, varE=1.43067\n",
      "Best model saved at epoch 110 with best E=-10.06542+0.10228j, varE=1.33623\n",
      "step: 110, loss: 0.97894, mean energy: -10.06542+0.10228j, varE: 1.33623\n",
      "Best model saved at epoch 118 with best E=-10.07930+0.24864j, varE=1.91582\n",
      "step: 120, loss: 4.64287, mean energy: -9.51024+0.18756j, varE: 2.46430\n",
      "Best model saved at epoch 123 with best E=-10.26862-0.10851j, varE=1.19817\n",
      "step: 130, loss: 0.32282, mean energy: -9.84001+0.10028j, varE: 2.55672\n",
      "step: 140, loss: 3.27416, mean energy: -10.05903-0.32850j, varE: 2.89462\n",
      "Best model saved at epoch 150 with best E=-10.44569-0.14347j, varE=2.03914\n",
      "step: 150, loss: 1.23441, mean energy: -10.44569-0.14347j, varE: 2.03914\n",
      "step: 160, loss: -0.73663, mean energy: -10.36417-0.09304j, varE: 1.46441\n",
      "Best model saved at epoch 161 with best E=-10.51325+0.15311j, varE=1.27704\n",
      "step: 170, loss: 1.00521, mean energy: -10.34654+0.06581j, varE: 1.02238\n",
      "step: 180, loss: 2.13647, mean energy: -10.39814+0.05360j, varE: 1.65164\n",
      "Best model saved at epoch 181 with best E=-10.62884-0.10629j, varE=0.90647\n",
      "Best model saved at epoch 184 with best E=-10.66088-0.02325j, varE=0.86691\n",
      "Best model saved at epoch 187 with best E=-10.77634-0.03079j, varE=0.76996\n",
      "step: 190, loss: -0.33031, mean energy: -10.68963+0.04616j, varE: 0.82040\n",
      "Best model saved at epoch 192 with best E=-10.78481-0.00680j, varE=0.49678\n",
      "Best model saved at epoch 196 with best E=-10.80763+0.12782j, varE=0.67845\n",
      "Best model saved at epoch 197 with best E=-10.89938+0.03282j, varE=0.60176\n",
      "step: 200, loss: 4.24632, mean energy: -10.60200-0.06326j, varE: 1.19967\n",
      "step: 210, loss: 4.06969, mean energy: -10.39771-0.09160j, varE: 2.46049\n",
      "step: 220, loss: -0.09005, mean energy: -9.89242+0.22431j, varE: 3.42389\n",
      "step: 230, loss: 4.67635, mean energy: -10.36855+0.01679j, varE: 1.38129\n",
      "step: 240, loss: -3.24972, mean energy: -7.14183-0.00421j, varE: 6.07811\n",
      "step: 250, loss: -4.15072, mean energy: -7.49550+0.24058j, varE: 4.92765\n",
      "step: 260, loss: -4.18061, mean energy: -9.71089-0.06100j, varE: 2.15830\n",
      "step: 270, loss: -2.12872, mean energy: -10.41361+0.05454j, varE: 1.24637\n",
      "step: 280, loss: 1.57931, mean energy: -10.35387-0.07260j, varE: 1.30429\n",
      "step: 290, loss: 2.30254, mean energy: -10.83061-0.18295j, varE: 0.77552\n",
      "Best model saved at epoch 291 with best E=-10.92819+0.13078j, varE=0.73561\n",
      "step: 300, loss: 3.16379, mean energy: -10.56500+0.11280j, varE: 1.12440\n",
      "Best model saved at epoch 302 with best E=-10.94627+0.10391j, varE=1.25142\n",
      "Best model saved at epoch 303 with best E=-10.99899+0.03342j, varE=0.44462\n",
      "step: 310, loss: 2.98969, mean energy: -10.18161+0.03338j, varE: 1.26237\n",
      "step: 320, loss: -2.80283, mean energy: -10.22126-0.07708j, varE: 1.62080\n",
      "Best model saved at epoch 329 with best E=-11.15615-0.07761j, varE=0.79736\n",
      "step: 330, loss: -0.03873, mean energy: -10.89695+0.09150j, varE: 1.02877\n",
      "Best model saved at epoch 336 with best E=-11.18832-0.02233j, varE=0.47563\n",
      "step: 340, loss: -1.09917, mean energy: -11.12261-0.08950j, varE: 0.60826\n",
      "Best model saved at epoch 346 with best E=-11.21533-0.04831j, varE=0.52148\n",
      "Best model saved at epoch 347 with best E=-11.22162+0.03640j, varE=0.17883\n",
      "Best model saved at epoch 350 with best E=-11.23724+0.01042j, varE=0.42849\n",
      "step: 350, loss: 0.20475, mean energy: -11.23724+0.01042j, varE: 0.42849\n",
      "Best model saved at epoch 355 with best E=-11.26821-0.01901j, varE=0.24191\n",
      "Best model saved at epoch 359 with best E=-11.28491-0.00538j, varE=0.13054\n",
      "step: 360, loss: -1.11637, mean energy: -11.24824-0.03827j, varE: 0.22269\n",
      "Best model saved at epoch 361 with best E=-11.33324-0.05819j, varE=0.13647\n",
      "step: 370, loss: -1.26405, mean energy: -11.23125+0.01446j, varE: 0.21961\n",
      "Best model saved at epoch 371 with best E=-11.35323-0.01203j, varE=0.10111\n",
      "Best model saved at epoch 380 with best E=-11.35881-0.02791j, varE=0.52270\n",
      "step: 380, loss: 0.47495, mean energy: -11.35881-0.02791j, varE: 0.52270\n",
      "step: 390, loss: -1.19646, mean energy: -11.14421-0.05151j, varE: 0.37797\n",
      "step: 400, loss: -1.12408, mean energy: -11.11557-0.06918j, varE: 0.85991\n",
      "step: 410, loss: -0.11580, mean energy: -11.22298-0.03731j, varE: 0.68591\n",
      "Best model saved at epoch 420 with best E=-11.36112+0.02033j, varE=0.20888\n",
      "step: 420, loss: 0.44091, mean energy: -11.36112+0.02033j, varE: 0.20888\n",
      "step: 430, loss: 0.55046, mean energy: -11.27664-0.02489j, varE: 0.09490\n",
      "Best model saved at epoch 434 with best E=-11.37317-0.02014j, varE=0.14772\n",
      "Best model saved at epoch 439 with best E=-11.38520+0.01461j, varE=0.11200\n",
      "step: 440, loss: -0.08385, mean energy: -11.30811+0.00688j, varE: 0.02730\n",
      "Best model saved at epoch 450 with best E=-11.40731+0.02115j, varE=0.24439\n",
      "step: 450, loss: -1.51220, mean energy: -11.40731+0.02115j, varE: 0.24439\n",
      "step: 460, loss: 0.20381, mean energy: -11.33585+0.01053j, varE: 0.02113\n",
      "step: 470, loss: 0.04494, mean energy: -11.34195+0.00852j, varE: 0.04116\n",
      "step: 480, loss: -0.21869, mean energy: -11.27001-0.01195j, varE: 0.13825\n",
      "step: 490, loss: 6.07249, mean energy: -11.50944-0.23038j, varE: 5.57052\n",
      "Best model saved at epoch 500 with best E=-11.51463-0.11825j, varE=2.53561\n",
      "step: 500, loss: 1.83736, mean energy: -11.51463-0.11825j, varE: 2.53561\n",
      "Total time taken: 11.795\n"
     ]
    }
   ],
   "source": [
    "#NO GRADIENT CLIPPING \n",
    "cell_type = 'HypGRU'\n",
    "hidden_units = 57\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "nsteps=505\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.55,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

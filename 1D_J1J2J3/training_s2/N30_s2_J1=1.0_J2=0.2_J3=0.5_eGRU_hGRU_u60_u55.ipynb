{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8c7463",
   "metadata": {},
   "source": [
    "# 1D J1J2J3: (J2=0.2, J3=0.5) - 2nd set of experiments\n",
    "\n",
    "This notebook is part of the work arXiv:2505.22083 (https://arxiv.org/abs/2505.22083), \"Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz\". Code written by HLD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9abff75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 15:39:15.950261: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../utility')\n",
    "from j1j2j3_hyprnn_train_loop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fd866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_exact = -14.640825798\n",
    "syssize = 30 #30 is divisible by both 2 and 3\n",
    "nssamples = 50\n",
    "J1 = 1.0\n",
    "J2 = 0.2\n",
    "J3 = 0.5\n",
    "var_tol = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f89e",
   "metadata": {},
   "source": [
    "# EuclGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6ddbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_eucl_wf at 0x1a765ffd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 60\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "wf_egru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914a5e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.66049, mean energy: 11.17103+0.45299j, varE: 1.69466\n",
      "step: 10, loss: -1.99533, mean energy: -1.15793+0.15225j, varE: 10.50147\n",
      "step: 20, loss: -0.45963, mean energy: -3.81849+0.18042j, varE: 7.21377\n",
      "step: 30, loss: -2.63721, mean energy: -6.24473+0.21212j, varE: 9.12473\n",
      "step: 40, loss: -4.70173, mean energy: -9.74107-0.17182j, varE: 4.82042\n",
      "Best model saved at epoch 42 with best E=-9.89557-0.01321j, varE=2.18269\n",
      "Best model saved at epoch 46 with best E=-10.17657-0.26217j, varE=0.46003\n",
      "step: 50, loss: 0.20715, mean energy: -10.15023-0.16776j, varE: 0.72845\n",
      "Best model saved at epoch 52 with best E=-10.18415-0.10455j, varE=0.38929\n",
      "step: 60, loss: -0.02691, mean energy: -10.12712-0.01215j, varE: 0.59969\n",
      "step: 70, loss: 0.06728, mean energy: -10.09655-0.03140j, varE: 0.20407\n",
      "step: 80, loss: -0.53753, mean energy: -10.06489+0.00839j, varE: 0.58700\n",
      "step: 90, loss: 1.02023, mean energy: -9.78108+0.08925j, varE: 1.12993\n",
      "Best model saved at epoch 95 with best E=-10.28242-0.18546j, varE=0.91368\n",
      "step: 100, loss: -0.37145, mean energy: -10.41280+0.21049j, varE: 4.22338\n",
      "Best model saved at epoch 104 with best E=-11.14022-0.23316j, varE=2.61456\n",
      "step: 110, loss: -7.15878, mean energy: -11.77569+0.35958j, varE: 6.38037\n",
      "step: 120, loss: -0.18919, mean energy: -11.79294-0.23269j, varE: 6.81645\n",
      "Best model saved at epoch 127 with best E=-11.91647+0.04903j, varE=2.73408\n",
      "step: 130, loss: -2.77904, mean energy: -11.86383+0.31089j, varE: 3.65308\n",
      "Best model saved at epoch 134 with best E=-12.28945-0.01912j, varE=1.49396\n",
      "Best model saved at epoch 135 with best E=-12.29585-0.10234j, varE=2.64489\n",
      "Best model saved at epoch 138 with best E=-13.05527+0.13562j, varE=2.72479\n",
      "step: 140, loss: 2.90891, mean energy: -12.93127+0.18143j, varE: 4.97366\n",
      "step: 150, loss: 0.63180, mean energy: -12.74354+0.03974j, varE: 3.34646\n",
      "step: 160, loss: 2.61153, mean energy: -12.45972+0.11284j, varE: 2.46482\n",
      "Best model saved at epoch 166 with best E=-13.19085+0.05242j, varE=2.07410\n",
      "step: 170, loss: 6.18489, mean energy: -12.98449-0.23251j, varE: 4.68093\n",
      "step: 180, loss: 5.92648, mean energy: -12.07993-0.05875j, varE: 2.33313\n",
      "step: 190, loss: -2.57594, mean energy: -13.70589+0.02017j, varE: 3.95834\n",
      "Best model saved at epoch 195 with best E=-13.21918+0.05347j, varE=2.18917\n",
      "Best model saved at epoch 196 with best E=-13.32905-0.13633j, varE=1.68962\n",
      "Best model saved at epoch 198 with best E=-13.40666+0.06821j, varE=1.96218\n",
      "step: 200, loss: -1.60062, mean energy: -13.12393+0.10115j, varE: 1.83923\n",
      "Best model saved at epoch 204 with best E=-13.55838+0.03312j, varE=2.60514\n",
      "Best model saved at epoch 206 with best E=-13.96702+0.04359j, varE=1.66322\n",
      "Best model saved at epoch 208 with best E=-14.00487-0.06568j, varE=2.27278\n",
      "step: 210, loss: -1.74443, mean energy: -13.79819-0.07814j, varE: 1.69038\n",
      "Best model saved at epoch 211 with best E=-14.00531-0.06784j, varE=2.12133\n",
      "Best model saved at epoch 215 with best E=-14.09794-0.05257j, varE=2.11366\n",
      "Best model saved at epoch 217 with best E=-14.13115+0.03574j, varE=1.84473\n",
      "step: 220, loss: -7.53850, mean energy: -13.55865-0.01606j, varE: 2.07994\n",
      "Best model saved at epoch 226 with best E=-14.14592+0.00071j, varE=1.58268\n",
      "Best model saved at epoch 228 with best E=-14.42201-0.04570j, varE=1.94796\n",
      "Best model saved at epoch 230 with best E=-14.42208+0.03798j, varE=1.04862\n",
      "step: 230, loss: -2.55141, mean energy: -14.42208+0.03798j, varE: 1.04862\n",
      "Best model saved at epoch 240 with best E=-14.44911+0.06205j, varE=1.08824\n",
      "step: 240, loss: 1.90286, mean energy: -14.44911+0.06205j, varE: 1.08824\n",
      "Best model saved at epoch 244 with best E=-14.55171-0.04190j, varE=1.08214\n",
      "Best model saved at epoch 250 with best E=-14.60358-0.07163j, varE=0.76965\n",
      "step: 250, loss: -0.42892, mean energy: -14.60358-0.07163j, varE: 0.76965\n",
      "step: 260, loss: -2.98158, mean energy: -14.17032+0.05982j, varE: 1.36917\n",
      "step: 270, loss: 4.45232, mean energy: -13.96644+0.03683j, varE: 1.55884\n",
      "step: 280, loss: 0.37183, mean energy: -14.53197+0.02501j, varE: 1.48355\n",
      "Best model saved at epoch 281 with best E=-14.74255+0.03247j, varE=2.11783\n",
      "step: 290, loss: -3.11624, mean energy: -14.40817-0.08308j, varE: 1.21343\n",
      "step: 300, loss: 0.04524, mean energy: -14.37228+0.02413j, varE: 1.06302\n",
      "step: 310, loss: -0.92511, mean energy: -14.48656-0.09176j, varE: 1.05150\n",
      "Best model saved at epoch 315 with best E=-14.81569-0.14650j, varE=1.91389\n",
      "step: 320, loss: 4.92358, mean energy: -14.61468+0.00490j, varE: 1.50517\n",
      "step: 330, loss: -3.94788, mean energy: -14.42940-0.01888j, varE: 0.94445\n",
      "step: 340, loss: -0.65205, mean energy: -14.51193+0.04081j, varE: 0.77940\n",
      "Best model saved at epoch 345 with best E=-14.88793-0.11312j, varE=1.13538\n",
      "step: 350, loss: 1.57059, mean energy: -14.60645-0.03637j, varE: 0.82682\n",
      "Total time taken: 1.925\n"
     ]
    }
   ],
   "source": [
    "nsteps = 351\n",
    "start = time.time()\n",
    "\n",
    "mE, vE = run_J1J2J3(wf=wf_egru, numsteps=nsteps, systemsize=syssize, var_tol=3.0, J1_  = J1, \n",
    "                   J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                  numsamples = nssamples, learningrate = 1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587abf4",
   "metadata": {},
   "source": [
    "# HypGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5339f77-ea5e-4b4a-9fd3-bc83f2491763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -3.70720, mean energy: 10.34374-0.60345j, varE: 4.60298\n",
      "step: 10, loss: 1.08876, mean energy: -1.98504+0.07080j, varE: 9.33381\n",
      "step: 20, loss: 4.13452, mean energy: -1.86714+0.42712j, varE: 10.54214\n",
      "step: 30, loss: -5.93134, mean energy: -4.61488+0.02444j, varE: 12.55273\n",
      "step: 40, loss: 0.78404, mean energy: -9.48739+0.09153j, varE: 9.06663\n",
      "step: 50, loss: 5.36865, mean energy: -11.21624-0.03758j, varE: 6.57377\n",
      "step: 60, loss: 0.00812, mean energy: -11.47818+0.03909j, varE: 6.91036\n",
      "step: 70, loss: -1.80083, mean energy: -12.79751+0.00483j, varE: 5.08553\n",
      "step: 80, loss: -5.08958, mean energy: -13.03098-0.01217j, varE: 2.42115\n",
      "Best model saved at epoch 84 with best E=-13.42585-0.16812j, varE=1.69840\n",
      "step: 90, loss: -2.89160, mean energy: -13.04657+0.19909j, varE: 2.37322\n",
      "step: 100, loss: 1.24956, mean energy: -13.26341+0.00827j, varE: 4.19102\n",
      "step: 110, loss: 0.14029, mean energy: -13.42810+0.05461j, varE: 2.71722\n",
      "Best model saved at epoch 113 with best E=-13.59780+0.26976j, varE=1.83796\n",
      "step: 120, loss: 4.91045, mean energy: -13.24100-0.04200j, varE: 2.47961\n",
      "step: 130, loss: 0.22856, mean energy: -13.72739-0.02414j, varE: 2.81917\n",
      "step: 140, loss: 0.98834, mean energy: -13.43974-0.04659j, varE: 2.90100\n",
      "Best model saved at epoch 141 with best E=-13.70979+0.04727j, varE=1.70437\n",
      "Best model saved at epoch 150 with best E=-13.96422-0.01813j, varE=0.96459\n",
      "step: 150, loss: -0.09389, mean energy: -13.96422-0.01813j, varE: 0.96459\n",
      "Best model saved at epoch 151 with best E=-14.03463+0.02412j, varE=1.60854\n",
      "step: 160, loss: 0.41238, mean energy: -13.83751-0.03193j, varE: 1.15651\n",
      "step: 170, loss: -3.29260, mean energy: -13.79821+0.03977j, varE: 1.08041\n",
      "step: 180, loss: -0.34351, mean energy: -13.41424+0.02925j, varE: 1.63836\n",
      "step: 190, loss: 4.51067, mean energy: -14.00072+0.11187j, varE: 1.01591\n",
      "Best model saved at epoch 192 with best E=-14.05264+0.11499j, varE=1.08633\n",
      "Best model saved at epoch 195 with best E=-14.22446+0.04634j, varE=1.47668\n",
      "step: 200, loss: 0.46259, mean energy: -14.06848+0.08927j, varE: 0.47864\n",
      "Best model saved at epoch 208 with best E=-14.28549+0.06440j, varE=0.91286\n",
      "step: 210, loss: -2.36200, mean energy: -14.02209-0.07934j, varE: 1.11936\n",
      "step: 220, loss: -1.50269, mean energy: -13.68493-0.13816j, varE: 1.28932\n",
      "step: 230, loss: -0.91911, mean energy: -14.11459+0.14099j, varE: 1.47536\n",
      "step: 240, loss: -0.65791, mean energy: -13.78876+0.19382j, varE: 1.11080\n",
      "step: 250, loss: -0.39141, mean energy: -14.13027+0.09437j, varE: 0.36737\n",
      "Best model saved at epoch 255 with best E=-14.44092-0.12544j, varE=0.82334\n",
      "step: 260, loss: -2.44556, mean energy: -14.29161-0.03309j, varE: 0.70572\n",
      "step: 270, loss: 2.51611, mean energy: -14.25676+0.13005j, varE: 0.95565\n",
      "step: 280, loss: -2.61409, mean energy: -14.27671+0.06995j, varE: 0.37493\n",
      "Best model saved at epoch 290 with best E=-14.46729-0.05200j, varE=1.60060\n",
      "step: 290, loss: -3.05850, mean energy: -14.46729-0.05200j, varE: 1.60060\n",
      "step: 300, loss: -4.51576, mean energy: -14.02074-0.07115j, varE: 1.00044\n",
      "step: 310, loss: 2.30446, mean energy: -14.30477+0.03522j, varE: 0.89433\n",
      "step: 320, loss: 6.66423, mean energy: -14.33717+0.11342j, varE: 0.81885\n",
      "step: 330, loss: 0.94852, mean energy: -14.42920+0.00015j, varE: 0.49360\n",
      "Best model saved at epoch 333 with best E=-14.60127-0.14246j, varE=1.91621\n",
      "step: 340, loss: -4.08466, mean energy: -14.07301-0.10792j, varE: 0.83422\n",
      "Best model saved at epoch 348 with best E=-14.66453+0.03808j, varE=1.34367\n",
      "step: 350, loss: -1.73964, mean energy: -14.16207+0.08031j, varE: 1.11398\n"
     ]
    }
   ],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 55\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "nsteps=381\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.0,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

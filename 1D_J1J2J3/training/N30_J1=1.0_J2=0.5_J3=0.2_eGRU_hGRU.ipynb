{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15f370f-2248-48d6-a144-8719c2faaf51",
   "metadata": {},
   "source": [
    "# 1D J1J2J3 - (J2 = 0.5, J3 = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9abff75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 18:14:16.126445: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../utility')\n",
    "from j1j2j3_hyprnn_train_loop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fd866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_exact = -11.528738924\n",
    "syssize = 30 #30 is divisible by both 2 and 3\n",
    "nssamples = 50\n",
    "J1 = 1.0\n",
    "J2 = 0.5\n",
    "J3 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f89e",
   "metadata": {},
   "source": [
    "# EuclGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6ddbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_eucl_wf at 0x139716d20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 50\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "wf_egru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51370d5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -2.02383, mean energy: 11.19061-0.08891j, varE: 1.63867\n",
      "step: 10, loss: 0.93947, mean energy: 0.03734-0.24254j, varE: 5.26638\n",
      "step: 20, loss: -5.89878, mean energy: -2.73622+0.28560j, varE: 4.44916\n",
      "Best model saved at epoch 30 with best E=-3.38793-0.07352j, varE=1.58565\n",
      "step: 30, loss: 0.00983, mean energy: -3.38793-0.07352j, varE: 1.58565\n",
      "step: 40, loss: -1.38756, mean energy: 1.20342-0.08436j, varE: 3.62164\n",
      "step: 50, loss: -1.28471, mean energy: -3.80938-0.14759j, varE: 5.01474\n",
      "step: 60, loss: 3.63553, mean energy: -3.67075-0.01279j, varE: 5.62455\n",
      "step: 70, loss: -1.63371, mean energy: -5.36033+0.04209j, varE: 4.68594\n",
      "step: 80, loss: 0.81543, mean energy: -6.22563-0.19745j, varE: 4.91888\n",
      "step: 90, loss: -2.88732, mean energy: -6.73980-0.09485j, varE: 3.55534\n",
      "step: 100, loss: 0.50497, mean energy: -7.03941+0.21671j, varE: 3.50256\n",
      "step: 110, loss: -1.25108, mean energy: -7.79367-0.05131j, varE: 6.55727\n",
      "step: 120, loss: 2.37425, mean energy: -7.77708+0.11374j, varE: 3.79413\n",
      "Best model saved at epoch 127 with best E=-8.01139+0.02713j, varE=1.99372\n",
      "step: 130, loss: 3.79568, mean energy: -8.26345-0.25338j, varE: 8.86985\n",
      "Best model saved at epoch 132 with best E=-8.21336-0.00092j, varE=1.96170\n",
      "Best model saved at epoch 133 with best E=-8.24395+0.17032j, varE=1.96816\n",
      "Best model saved at epoch 137 with best E=-8.33779+0.14762j, varE=1.17566\n",
      "step: 140, loss: -2.68576, mean energy: -8.56883+0.52853j, varE: 6.93308\n",
      "Best model saved at epoch 146 with best E=-8.64183-0.11054j, varE=0.99040\n",
      "step: 150, loss: -4.71325, mean energy: -8.32404+0.11973j, varE: 2.96716\n",
      "Best model saved at epoch 153 with best E=-8.77575+0.10334j, varE=1.35174\n",
      "step: 160, loss: 5.29943, mean energy: -8.19092-0.05464j, varE: 2.27651\n",
      "step: 170, loss: -1.74884, mean energy: -8.67131+0.00856j, varE: 3.75538\n",
      "Best model saved at epoch 178 with best E=-8.99944+0.09569j, varE=1.12961\n",
      "step: 180, loss: -2.87984, mean energy: -8.84012-0.00014j, varE: 2.24951\n",
      "Best model saved at epoch 185 with best E=-9.12532-0.03532j, varE=1.40059\n",
      "step: 190, loss: 3.54299, mean energy: -9.53341+0.07888j, varE: 3.32980\n",
      "Best model saved at epoch 192 with best E=-9.24762-0.00200j, varE=1.89345\n",
      "Best model saved at epoch 193 with best E=-9.32286+0.01354j, varE=0.91548\n",
      "Best model saved at epoch 196 with best E=-9.39689-0.04178j, varE=1.27961\n",
      "step: 200, loss: 9.92526, mean energy: -9.77358+0.43118j, varE: 14.30058\n",
      "Best model saved at epoch 210 with best E=-9.50541-0.09671j, varE=1.88842\n",
      "step: 210, loss: -1.81321, mean energy: -9.50541-0.09671j, varE: 1.88842\n",
      "step: 220, loss: -6.07563, mean energy: -9.08988-0.01349j, varE: 1.33939\n",
      "Best model saved at epoch 223 with best E=-9.53863-0.00349j, varE=1.85050\n",
      "Best model saved at epoch 229 with best E=-9.64207+0.17320j, varE=1.67826\n",
      "step: 230, loss: -4.35136, mean energy: -9.51240+0.22375j, varE: 1.64748\n",
      "step: 240, loss: -5.61859, mean energy: -8.89282+0.12170j, varE: 2.36154\n",
      "Best model saved at epoch 243 with best E=-9.65136+0.09239j, varE=0.71445\n",
      "Best model saved at epoch 249 with best E=-9.65894-0.01018j, varE=1.47253\n",
      "step: 250, loss: -5.81581, mean energy: -9.28697+0.15220j, varE: 1.72245\n",
      "Best model saved at epoch 252 with best E=-9.78728-0.03309j, varE=1.36751\n",
      "step: 260, loss: -0.15516, mean energy: -9.61095-0.05050j, varE: 2.14228\n",
      "step: 270, loss: -2.33733, mean energy: -9.71321+0.04469j, varE: 1.35481\n",
      "step: 280, loss: -2.55063, mean energy: -9.64787+0.02444j, varE: 0.61998\n",
      "Total time taken: 2.786\n"
     ]
    }
   ],
   "source": [
    "nsteps = 281\n",
    "start = time.time()\n",
    "\n",
    "mE, vE = run_J1J2J3(wf=wf_egru, numsteps=nsteps, systemsize=syssize, var_tol=2.0, J1_  = J1, \n",
    "                   J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                  numsamples = nssamples, learningrate = 1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587abf4",
   "metadata": {},
   "source": [
    "# HypGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d7e7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_hyp_wf at 0x12f7813a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 50\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "wf_hgru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8615c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -4.37091, mean energy: 8.07094-0.55491j, varE: 6.08936\n",
      "step: 10, loss: 0.28780, mean energy: -2.12154-0.42162j, varE: 7.17037\n",
      "step: 20, loss: -2.51543, mean energy: -4.69914-0.04085j, varE: 7.28097\n",
      "step: 30, loss: 4.74477, mean energy: -6.07641-0.18759j, varE: 9.50369\n",
      "step: 40, loss: 1.26389, mean energy: -6.38038+0.11550j, varE: 4.40316\n",
      "step: 50, loss: -4.04565, mean energy: -7.00447+0.24358j, varE: 3.51698\n",
      "step: 60, loss: -1.45188, mean energy: -7.47132-0.26957j, varE: 4.50283\n",
      "step: 70, loss: -1.27217, mean energy: -8.61914+0.13008j, varE: 2.76471\n",
      "step: 80, loss: -2.30238, mean energy: -9.25112-0.04434j, varE: 2.83964\n",
      "step: 90, loss: -1.56491, mean energy: -9.47349+0.07441j, varE: 2.21748\n",
      "Best model saved at epoch 95 with best E=-9.51710-0.01719j, varE=1.86352\n",
      "Best model saved at epoch 100 with best E=-9.63733-0.05341j, varE=1.56622\n",
      "step: 100, loss: 0.19627, mean energy: -9.63733-0.05341j, varE: 1.56622\n",
      "Best model saved at epoch 101 with best E=-9.80958-0.17698j, varE=1.23565\n",
      "Best model saved at epoch 109 with best E=-10.09133+0.09233j, varE=1.39680\n",
      "step: 110, loss: 2.39580, mean energy: -9.46032+0.14932j, varE: 3.27966\n",
      "Best model saved at epoch 112 with best E=-10.18519+0.17133j, varE=1.51090\n",
      "Best model saved at epoch 116 with best E=-10.18964+0.01812j, varE=1.72851\n",
      "Best model saved at epoch 118 with best E=-10.40798+0.05176j, varE=1.10674\n",
      "step: 120, loss: 0.09273, mean energy: -10.16001-0.04487j, varE: 1.27846\n",
      "Best model saved at epoch 126 with best E=-10.41971+0.10596j, varE=0.95114\n",
      "Best model saved at epoch 127 with best E=-10.48700-0.03227j, varE=0.91643\n",
      "Best model saved at epoch 129 with best E=-10.51996+0.09352j, varE=1.65117\n",
      "step: 130, loss: -0.58023, mean energy: -10.68202-0.05195j, varE: 2.19272\n",
      "step: 140, loss: -1.10119, mean energy: -10.42847+0.06162j, varE: 2.69165\n",
      "Best model saved at epoch 144 with best E=-10.59162-0.13006j, varE=0.89369\n",
      "Best model saved at epoch 148 with best E=-10.64228+0.00861j, varE=0.56371\n",
      "step: 150, loss: -0.62341, mean energy: -10.50382+0.08357j, varE: 0.75306\n",
      "step: 160, loss: 0.52608, mean energy: -10.62209+0.02206j, varE: 0.71351\n",
      "Best model saved at epoch 161 with best E=-10.74233-0.11138j, varE=0.70720\n",
      "Best model saved at epoch 167 with best E=-10.85467-0.04183j, varE=0.38388\n",
      "step: 170, loss: -0.89394, mean energy: -10.41535+0.11997j, varE: 2.03651\n",
      "step: 180, loss: -0.47115, mean energy: -10.72434+0.01501j, varE: 0.50626\n",
      "Best model saved at epoch 186 with best E=-10.88948+0.01699j, varE=0.27470\n",
      "step: 190, loss: 0.25333, mean energy: -10.71190+0.01716j, varE: 0.53459\n",
      "step: 200, loss: -0.16777, mean energy: -10.78909+0.01490j, varE: 0.26872\n",
      "step: 210, loss: -1.63979, mean energy: -10.65363+0.04140j, varE: 0.22333\n",
      "step: 220, loss: 0.15559, mean energy: -10.74941+0.04344j, varE: 0.12913\n",
      "step: 230, loss: -1.27637, mean energy: -10.60180-0.02338j, varE: 0.53077\n",
      "Best model saved at epoch 231 with best E=-10.89163+0.01952j, varE=0.20585\n",
      "step: 240, loss: -0.31018, mean energy: -10.82877+0.02503j, varE: 0.13888\n",
      "step: 250, loss: -0.96755, mean energy: -10.85623+0.00492j, varE: 0.15790\n",
      "Best model saved at epoch 258 with best E=-10.92380-0.05997j, varE=0.24122\n",
      "Best model saved at epoch 259 with best E=-10.92548-0.07744j, varE=0.41378\n",
      "step: 260, loss: 0.94708, mean energy: -10.78763+0.00759j, varE: 0.11746\n",
      "Best model saved at epoch 266 with best E=-10.93812-0.01704j, varE=0.17530\n",
      "step: 270, loss: -0.65915, mean energy: -10.64907+0.00173j, varE: 0.13191\n",
      "Best model saved at epoch 272 with best E=-10.95408-0.02680j, varE=0.33744\n",
      "step: 280, loss: -0.08629, mean energy: -10.86156+0.01624j, varE: 0.12181\n",
      "Total time taken: 15.14\n"
     ]
    }
   ],
   "source": [
    "nsteps=281\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.0,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe00995-211b-4160-ae88-ba67b6e0ad20",
   "metadata": {},
   "source": [
    "# 1D J1J2J3 - (J2 = 0.2, J3 = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9abff75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 13:16:28.384038: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../utility')\n",
    "from j1j2j3_hyprnn_train_loop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fd866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_exact =  -12.943044\n",
    "syssize = 30 #30 is divisible by both 2 and 3\n",
    "nssamples = 50\n",
    "J1 = 1.0\n",
    "J2 = 0.2\n",
    "J3 = 0.2\n",
    "var_tol = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f89e",
   "metadata": {},
   "source": [
    "# EuclGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6ddbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_eucl_wf at 0x13b8ea330>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 50\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "wf_egru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51370d5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.52725, mean energy: 9.30351-0.10678j, varE: 0.97178\n",
      "step: 10, loss: 1.11483, mean energy: 0.41267+0.11279j, varE: 4.53995\n",
      "step: 20, loss: -1.80723, mean energy: -1.87622+0.08837j, varE: 4.30389\n",
      "step: 30, loss: 8.04846, mean energy: -4.21251-0.37977j, varE: 6.95573\n",
      "step: 40, loss: 11.87289, mean energy: -7.39517-0.18724j, varE: 8.14812\n",
      "step: 50, loss: -21.19988, mean energy: -8.36968-0.20418j, varE: 7.08206\n",
      "step: 60, loss: -8.16107, mean energy: -9.35392+0.07527j, varE: 2.02089\n",
      "Best model saved at epoch 63 with best E=-9.17541-0.02197j, varE=1.25816\n",
      "step: 70, loss: -1.03887, mean energy: -9.17897+0.13475j, varE: 2.01364\n",
      "Best model saved at epoch 76 with best E=-9.60213+0.12280j, varE=0.95414\n",
      "step: 80, loss: 1.65752, mean energy: -9.39868-0.15714j, varE: 1.01491\n",
      "Best model saved at epoch 83 with best E=-9.60781-0.02183j, varE=1.06324\n",
      "Best model saved at epoch 87 with best E=-9.81678-0.05134j, varE=0.64076\n",
      "step: 90, loss: -1.31496, mean energy: -9.71226+0.02691j, varE: 2.05101\n",
      "Best model saved at epoch 96 with best E=-9.86120-0.08924j, varE=1.48499\n",
      "step: 100, loss: 2.47311, mean energy: -9.92946+0.16060j, varE: 3.13048\n",
      "step: 110, loss: 2.08105, mean energy: -9.40733+0.17302j, varE: 3.19946\n",
      "step: 120, loss: 3.40714, mean energy: -9.74170+0.04826j, varE: 4.00488\n",
      "Best model saved at epoch 124 with best E=-10.15082-0.03540j, varE=1.51915\n",
      "Best model saved at epoch 127 with best E=-10.45356-0.30129j, varE=1.27802\n",
      "step: 130, loss: 1.33435, mean energy: -10.15435-0.30686j, varE: 4.22964\n",
      "step: 140, loss: -7.39104, mean energy: -10.21417+0.09217j, varE: 2.33000\n",
      "step: 150, loss: 0.48751, mean energy: -9.91887-0.06324j, varE: 1.86704\n",
      "Best model saved at epoch 152 with best E=-10.47519-0.03296j, varE=1.17683\n",
      "step: 160, loss: -10.27578, mean energy: -9.85990-0.06252j, varE: 2.41355\n",
      "step: 170, loss: -2.03558, mean energy: -10.39667-0.03907j, varE: 1.92301\n",
      "Best model saved at epoch 178 with best E=-10.55307-0.09976j, varE=1.52137\n",
      "step: 180, loss: -2.32114, mean energy: -10.35804-0.07492j, varE: 1.03068\n",
      "Best model saved at epoch 181 with best E=-10.63087+0.05981j, varE=0.92841\n",
      "Best model saved at epoch 182 with best E=-10.73777-0.09358j, varE=0.68797\n",
      "step: 190, loss: -6.13900, mean energy: -10.59991-0.01077j, varE: 1.44600\n",
      "Best model saved at epoch 193 with best E=-10.79104+0.05638j, varE=1.56506\n",
      "step: 200, loss: -4.00986, mean energy: -10.51412-0.05141j, varE: 1.04277\n",
      "Best model saved at epoch 203 with best E=-10.81375-0.08520j, varE=1.64750\n",
      "Best model saved at epoch 205 with best E=-10.82456-0.15832j, varE=0.79598\n",
      "Best model saved at epoch 207 with best E=-10.84737+0.05694j, varE=1.18223\n",
      "step: 210, loss: 1.86989, mean energy: -10.46260+0.07423j, varE: 2.19096\n",
      "Best model saved at epoch 218 with best E=-10.89244+0.11562j, varE=0.75541\n",
      "step: 220, loss: -3.37861, mean energy: -10.61203+0.07630j, varE: 0.91190\n",
      "step: 230, loss: -0.95086, mean energy: -10.66447-0.09943j, varE: 0.40286\n",
      "step: 240, loss: 3.25536, mean energy: -10.81658-0.07254j, varE: 0.62977\n",
      "Best model saved at epoch 245 with best E=-10.92603-0.08366j, varE=0.84351\n",
      "step: 250, loss: 3.63079, mean energy: -10.69235-0.04776j, varE: 1.19948\n",
      "Best model saved at epoch 256 with best E=-10.93928-0.12893j, varE=0.90443\n",
      "step: 260, loss: 3.43245, mean energy: -10.75469-0.18839j, varE: 0.35331\n",
      "step: 270, loss: -5.15233, mean energy: -10.65007-0.04549j, varE: 0.88685\n",
      "step: 280, loss: -3.62656, mean energy: -10.71223+0.05610j, varE: 0.47872\n",
      "Total time taken: 2.233\n"
     ]
    }
   ],
   "source": [
    "nsteps = 281\n",
    "start = time.time()\n",
    "\n",
    "mE, vE = run_J1J2J3(wf=wf_egru, numsteps=nsteps, systemsize=syssize, var_tol=2.0, J1_  = J1, \n",
    "                   J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                  numsamples = nssamples, learningrate = 1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587abf4",
   "metadata": {},
   "source": [
    "# HypGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d7e7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_hyp_wf at 0x7fc644e5df70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 50\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "wf_hgru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd539aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -3.60030, mean energy: 6.62686-0.47945j, varE: 4.59493\n",
      "step: 10, loss: 0.53734, mean energy: -2.19978-0.09208j, varE: 6.08433\n",
      "step: 20, loss: -5.03879, mean energy: -3.51312+0.14260j, varE: 12.27086\n",
      "step: 30, loss: 0.19357, mean energy: -7.45753+0.07881j, varE: 4.93408\n",
      "step: 40, loss: -12.56826, mean energy: -8.26647+0.15125j, varE: 11.97608\n",
      "step: 50, loss: -0.43689, mean energy: -9.83519+0.59189j, varE: 4.86320\n",
      "step: 60, loss: 0.00280, mean energy: -8.84013+0.06346j, varE: 5.15384\n",
      "step: 70, loss: 0.07327, mean energy: -9.17404+0.11183j, varE: 4.12777\n",
      "step: 80, loss: 2.11300, mean energy: -10.90319+0.21577j, varE: 6.36499\n",
      "step: 90, loss: -1.18523, mean energy: -11.01257+0.30226j, varE: 5.88093\n",
      "Best model saved at epoch 96 with best E=-10.81692-0.08787j, varE=1.98602\n",
      "Best model saved at epoch 100 with best E=-11.33586-0.08391j, varE=1.67183\n",
      "step: 100, loss: 2.38579, mean energy: -11.33586-0.08391j, varE: 1.67183\n",
      "Best model saved at epoch 104 with best E=-11.52305+0.09653j, varE=1.93960\n",
      "step: 110, loss: -0.29279, mean energy: -11.00654+0.00447j, varE: 2.31670\n",
      "step: 120, loss: -3.42554, mean energy: -11.27646+0.02680j, varE: 2.34094\n",
      "Best model saved at epoch 125 with best E=-11.66529+0.09252j, varE=0.90479\n",
      "step: 130, loss: -3.34669, mean energy: -11.44740+0.05692j, varE: 3.06048\n",
      "Best model saved at epoch 133 with best E=-11.77190-0.02212j, varE=0.96119\n",
      "step: 140, loss: 6.53702, mean energy: -11.59657-0.10854j, varE: 2.12782\n",
      "Best model saved at epoch 150 with best E=-11.80593+0.02976j, varE=0.81145\n",
      "step: 150, loss: 0.46815, mean energy: -11.80593+0.02976j, varE: 0.81145\n",
      "Best model saved at epoch 157 with best E=-11.98663-0.00548j, varE=0.83788\n",
      "step: 160, loss: -1.55907, mean energy: -11.81501+0.04832j, varE: 1.62183\n",
      "step: 170, loss: -1.32443, mean energy: -11.86324-0.03713j, varE: 1.12925\n",
      "Best model saved at epoch 172 with best E=-12.01855+0.15048j, varE=1.25443\n",
      "step: 180, loss: -1.41253, mean energy: -11.95555-0.18207j, varE: 1.53296\n",
      "Best model saved at epoch 182 with best E=-12.15455+0.18868j, varE=1.23457\n",
      "step: 190, loss: -1.26611, mean energy: -12.00272+0.23087j, varE: 1.05731\n",
      "step: 200, loss: -1.28192, mean energy: -11.98705+0.04628j, varE: 0.61074\n",
      "step: 210, loss: -2.91920, mean energy: -11.40965+0.16148j, varE: 2.24370\n",
      "step: 220, loss: 0.84748, mean energy: -11.75120-0.05716j, varE: 1.33732\n",
      "step: 230, loss: 0.06915, mean energy: -11.86819+0.14729j, varE: 1.03705\n",
      "step: 240, loss: -2.53307, mean energy: -11.74478+0.21274j, varE: 1.40434\n",
      "Best model saved at epoch 242 with best E=-12.23774+0.04917j, varE=0.65901\n",
      "step: 250, loss: -1.51943, mean energy: -12.01386+0.07692j, varE: 0.45355\n",
      "step: 260, loss: 1.39813, mean energy: -11.82951-0.01177j, varE: 1.59956\n",
      "step: 270, loss: 1.72775, mean energy: -12.05602-0.00324j, varE: 0.67049\n",
      "step: 280, loss: -8.06829, mean energy: -11.77759-0.28032j, varE: 16.20514\n",
      "Total time taken: 8.018\n"
     ]
    }
   ],
   "source": [
    "nsteps=281\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.0,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83eba79a",
   "metadata": {},
   "source": [
    "# 1D J1J2J3: (J2=0.5, J3=0.2) - 2nd set of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9abff75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 23:03:16.791237: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../utility')\n",
    "from j1j2j3_hyprnn_train_loop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fd866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_exact = -11.528738924\n",
    "syssize = 30 #30 is divisible by both 2 and 3\n",
    "nssamples = 50\n",
    "J1 = 1.0\n",
    "J2 = 0.5\n",
    "J3 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f89e",
   "metadata": {},
   "source": [
    "# EuclGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6ddbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_eucl_wf at 0x19ef43b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 60\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "wf_egru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632c32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.49794, mean energy: 11.29978+0.37143j, varE: 1.40917\n",
      "step: 10, loss: -3.51608, mean energy: -1.16016+0.02446j, varE: 8.54640\n",
      "step: 20, loss: -3.68297, mean energy: -3.55704+0.13036j, varE: 6.26923\n",
      "step: 30, loss: -3.20737, mean energy: -5.00485+0.19399j, varE: 3.68202\n",
      "step: 40, loss: -7.49615, mean energy: -6.45960-0.13954j, varE: 4.96866\n",
      "Best model saved at epoch 50 with best E=-8.42214-0.14513j, varE=1.92175\n",
      "step: 50, loss: -1.40786, mean energy: -8.42214-0.14513j, varE: 1.92175\n",
      "step: 60, loss: 1.89986, mean energy: -7.94941+0.34825j, varE: 2.71834\n",
      "Best model saved at epoch 69 with best E=-8.84826+0.14143j, varE=1.69624\n",
      "Best model saved at epoch 70 with best E=-9.01429-0.04766j, varE=1.96896\n",
      "step: 70, loss: 0.50349, mean energy: -9.01429-0.04766j, varE: 1.96896\n",
      "Best model saved at epoch 80 with best E=-9.40039+0.06367j, varE=1.73536\n",
      "step: 80, loss: 1.92274, mean energy: -9.40039+0.06367j, varE: 1.73536\n",
      "Best model saved at epoch 85 with best E=-9.40264-0.04374j, varE=1.56997\n",
      "Best model saved at epoch 87 with best E=-9.42271-0.17432j, varE=1.50133\n",
      "Best model saved at epoch 88 with best E=-9.66796-0.19733j, varE=1.76410\n",
      "step: 90, loss: -5.44909, mean energy: -9.31665-0.17392j, varE: 2.63028\n",
      "step: 100, loss: 4.41608, mean energy: -8.97789+0.11270j, varE: 2.62588\n",
      "Best model saved at epoch 102 with best E=-9.76456+0.04946j, varE=1.69599\n",
      "Best model saved at epoch 104 with best E=-9.91954-0.04729j, varE=1.55839\n",
      "step: 110, loss: 1.90388, mean energy: -9.20932+0.08492j, varE: 2.43433\n",
      "Best model saved at epoch 116 with best E=-9.97664+0.08466j, varE=1.69748\n",
      "Best model saved at epoch 118 with best E=-10.22097-0.15806j, varE=1.04557\n",
      "step: 120, loss: -2.51931, mean energy: -9.96998+0.02209j, varE: 1.60814\n",
      "step: 130, loss: -0.98347, mean energy: -8.93242-0.05886j, varE: 2.29198\n",
      "Best model saved at epoch 132 with best E=-10.28063-0.01378j, varE=1.61086\n",
      "step: 140, loss: -0.76872, mean energy: -8.90820+0.01429j, varE: 1.75719\n",
      "step: 150, loss: -1.65930, mean energy: -9.73807-0.03136j, varE: 1.57856\n",
      "step: 160, loss: -2.86017, mean energy: -9.94977+0.00082j, varE: 2.05881\n",
      "step: 170, loss: -1.66465, mean energy: -10.00374+0.02044j, varE: 0.92406\n",
      "Best model saved at epoch 176 with best E=-10.30153-0.11704j, varE=1.48781\n",
      "Best model saved at epoch 178 with best E=-10.30773-0.15639j, varE=0.78613\n",
      "step: 180, loss: -2.18925, mean energy: -10.18229-0.14447j, varE: 1.66898\n",
      "Best model saved at epoch 182 with best E=-10.46385-0.09828j, varE=1.53928\n",
      "step: 190, loss: 0.11630, mean energy: -9.96234-0.06957j, varE: 1.49451\n",
      "Best model saved at epoch 196 with best E=-10.56643-0.10645j, varE=1.11858\n",
      "step: 200, loss: -1.91611, mean energy: -10.28903-0.19435j, varE: 1.06827\n",
      "step: 210, loss: -4.99702, mean energy: -10.34458-0.00451j, varE: 1.60601\n",
      "step: 220, loss: 6.03685, mean energy: -10.56291-0.05218j, varE: 1.38272\n",
      "Best model saved at epoch 221 with best E=-10.70339-0.01963j, varE=1.10048\n",
      "step: 230, loss: -4.85110, mean energy: -10.42583-0.18577j, varE: 1.69938\n",
      "Best model saved at epoch 233 with best E=-10.77690-0.00683j, varE=1.07767\n",
      "Best model saved at epoch 236 with best E=-10.88924+0.02615j, varE=1.51815\n",
      "step: 240, loss: -1.96411, mean energy: -10.79381-0.09762j, varE: 1.14873\n",
      "Best model saved at epoch 247 with best E=-10.93115-0.20581j, varE=1.02579\n",
      "step: 250, loss: -4.71397, mean energy: -10.79317-0.18577j, varE: 1.03202\n",
      "Best model saved at epoch 253 with best E=-11.06823-0.00985j, varE=0.87022\n",
      "Best model saved at epoch 256 with best E=-11.08785-0.04885j, varE=0.30434\n",
      "step: 260, loss: 3.06706, mean energy: -11.02727-0.13809j, varE: 0.63848\n",
      "Best model saved at epoch 261 with best E=-11.10349-0.01389j, varE=0.52752\n",
      "Best model saved at epoch 262 with best E=-11.27316-0.08421j, varE=0.45792\n",
      "step: 270, loss: 1.19643, mean energy: -11.22910-0.04184j, varE: 0.21848\n",
      "Best model saved at epoch 272 with best E=-11.32454+0.07546j, varE=0.54006\n",
      "step: 280, loss: -0.09423, mean energy: -11.04778-0.00513j, varE: 0.22202\n",
      "Best model saved at epoch 287 with best E=-11.32852-0.00064j, varE=0.20152\n",
      "step: 290, loss: 0.35218, mean energy: -11.31168-0.02356j, varE: 0.47862\n",
      "Best model saved at epoch 295 with best E=-11.36587+0.06405j, varE=0.27556\n",
      "step: 300, loss: -1.79060, mean energy: -11.10251+0.00664j, varE: 0.32815\n",
      "step: 310, loss: 0.49004, mean energy: -11.01993-0.02724j, varE: 0.99249\n",
      "step: 320, loss: 0.22801, mean energy: -11.14840-0.01039j, varE: 0.49831\n",
      "step: 330, loss: -2.13370, mean energy: -11.28612-0.07621j, varE: 0.24730\n",
      "step: 340, loss: 0.89883, mean energy: -11.32986-0.04177j, varE: 0.10215\n",
      "step: 350, loss: 0.90343, mean energy: -11.28756-0.02088j, varE: 0.21647\n",
      "Best model saved at epoch 355 with best E=-11.36952+0.04553j, varE=0.20141\n",
      "step: 360, loss: -0.02373, mean energy: -11.25057-0.04167j, varE: 1.12588\n",
      "Best model saved at epoch 364 with best E=-11.40407-0.01055j, varE=0.14394\n",
      "step: 370, loss: -1.60388, mean energy: -11.22172+0.01744j, varE: 0.22670\n",
      "Best model saved at epoch 373 with best E=-11.41122-0.02727j, varE=0.17131\n",
      "step: 380, loss: -0.84490, mean energy: -11.26892+0.01535j, varE: 0.21433\n",
      "Best model saved at epoch 389 with best E=-11.47059+0.03330j, varE=0.11308\n",
      "step: 390, loss: 1.89103, mean energy: -11.24287+0.04694j, varE: 0.37025\n",
      "step: 400, loss: 0.92618, mean energy: -11.34242-0.00073j, varE: 0.07229\n",
      "step: 410, loss: -0.68733, mean energy: -11.35546-0.05074j, varE: 0.07443\n",
      "step: 420, loss: 0.41206, mean energy: -11.22797+0.02799j, varE: 0.54230\n",
      "step: 430, loss: -0.63124, mean energy: -11.37903+0.04663j, varE: 0.07772\n",
      "step: 440, loss: 0.00995, mean energy: -11.32902-0.01423j, varE: 0.09537\n",
      "step: 450, loss: 0.42558, mean energy: -11.31219-0.02592j, varE: 0.13520\n",
      "step: 460, loss: -0.52220, mean energy: -11.43323+0.10169j, varE: 0.07466\n",
      "step: 470, loss: -0.30028, mean energy: -11.35925+0.00109j, varE: 0.18823\n",
      "step: 480, loss: 0.60057, mean energy: -11.32147-0.03466j, varE: 0.47632\n",
      "step: 490, loss: -0.30054, mean energy: -11.35581-0.00899j, varE: 0.03934\n",
      "step: 500, loss: -0.83580, mean energy: -11.37828+0.01774j, varE: 0.07513\n"
     ]
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 60\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "nsteps = 551\n",
    "start = time.time()\n",
    "\n",
    "mE, vE = run_J1J2J3(wf=wf_egru, numsteps=nsteps, systemsize=syssize, var_tol=2.0, J1_  = J1, \n",
    "                   J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                  numsamples = nssamples, learningrate = 1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587abf4",
   "metadata": {},
   "source": [
    "# HypGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bd1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.53725, mean energy: 11.52415-0.00719j, varE: 1.48318\n",
      "step: 10, loss: -0.06060, mean energy: -0.73598+0.21279j, varE: 8.52583\n",
      "step: 20, loss: 3.58000, mean energy: -2.54576+0.03392j, varE: 6.39923\n",
      "step: 30, loss: -2.26369, mean energy: -5.11180-0.21194j, varE: 4.70692\n",
      "step: 40, loss: -4.99415, mean energy: -6.65871-0.05175j, varE: 4.42478\n",
      "step: 50, loss: 2.27335, mean energy: -7.88731-0.20993j, varE: 3.59857\n",
      "Best model saved at epoch 52 with best E=-8.42810-0.03112j, varE=2.22999\n",
      "Best model saved at epoch 55 with best E=-8.54184-0.15340j, varE=2.54051\n",
      "Best model saved at epoch 60 with best E=-9.16329+0.07193j, varE=1.87824\n",
      "step: 60, loss: -2.48755, mean energy: -9.16329+0.07193j, varE: 1.87824\n",
      "Best model saved at epoch 62 with best E=-9.26904-0.04750j, varE=2.39053\n",
      "Best model saved at epoch 67 with best E=-9.44151-0.03871j, varE=2.32227\n",
      "Best model saved at epoch 68 with best E=-9.86594-0.15083j, varE=1.19312\n",
      "step: 70, loss: -2.30797, mean energy: -9.76865+0.07089j, varE: 2.55179\n",
      "step: 80, loss: -1.75036, mean energy: -9.34098-0.11800j, varE: 1.63284\n",
      "Best model saved at epoch 87 with best E=-9.89533-0.02321j, varE=1.00647\n",
      "step: 90, loss: -1.82702, mean energy: -9.53723-0.13498j, varE: 4.12660\n",
      "step: 100, loss: -5.94459, mean energy: -9.47133-0.00580j, varE: 2.58655\n",
      "Best model saved at epoch 109 with best E=-9.92978+0.00040j, varE=1.43067\n",
      "Best model saved at epoch 110 with best E=-10.06542+0.10228j, varE=1.33623\n",
      "step: 110, loss: 0.97894, mean energy: -10.06542+0.10228j, varE: 1.33623\n",
      "Best model saved at epoch 118 with best E=-10.07930+0.24864j, varE=1.91582\n",
      "step: 120, loss: 4.64287, mean energy: -9.51024+0.18756j, varE: 2.46430\n",
      "Best model saved at epoch 123 with best E=-10.26862-0.10851j, varE=1.19817\n",
      "step: 130, loss: 0.32282, mean energy: -9.84001+0.10028j, varE: 2.55672\n",
      "step: 140, loss: 3.27416, mean energy: -10.05903-0.32850j, varE: 2.89462\n",
      "Best model saved at epoch 150 with best E=-10.44569-0.14347j, varE=2.03914\n",
      "step: 150, loss: 1.23441, mean energy: -10.44569-0.14347j, varE: 2.03914\n",
      "step: 160, loss: -0.73663, mean energy: -10.36417-0.09304j, varE: 1.46441\n",
      "Best model saved at epoch 161 with best E=-10.51325+0.15311j, varE=1.27704\n",
      "step: 170, loss: 1.00521, mean energy: -10.34654+0.06581j, varE: 1.02238\n",
      "step: 180, loss: 2.13647, mean energy: -10.39814+0.05360j, varE: 1.65164\n",
      "Best model saved at epoch 181 with best E=-10.62884-0.10629j, varE=0.90647\n",
      "Best model saved at epoch 184 with best E=-10.66088-0.02325j, varE=0.86691\n",
      "Best model saved at epoch 187 with best E=-10.77634-0.03079j, varE=0.76996\n",
      "step: 190, loss: -0.33031, mean energy: -10.68963+0.04616j, varE: 0.82040\n",
      "Best model saved at epoch 192 with best E=-10.78481-0.00680j, varE=0.49678\n",
      "Best model saved at epoch 196 with best E=-10.80763+0.12782j, varE=0.67845\n",
      "Best model saved at epoch 197 with best E=-10.89938+0.03282j, varE=0.60176\n",
      "step: 200, loss: 4.24632, mean energy: -10.60200-0.06326j, varE: 1.19967\n",
      "step: 210, loss: 4.06969, mean energy: -10.39771-0.09160j, varE: 2.46049\n",
      "step: 220, loss: -0.09005, mean energy: -9.89242+0.22431j, varE: 3.42389\n",
      "step: 230, loss: 4.67635, mean energy: -10.36855+0.01679j, varE: 1.38129\n",
      "step: 240, loss: -3.24972, mean energy: -7.14183-0.00421j, varE: 6.07811\n",
      "step: 250, loss: -4.15072, mean energy: -7.49550+0.24058j, varE: 4.92765\n",
      "step: 260, loss: -4.18061, mean energy: -9.71089-0.06100j, varE: 2.15830\n",
      "step: 270, loss: -2.12872, mean energy: -10.41361+0.05454j, varE: 1.24637\n",
      "step: 280, loss: 1.57931, mean energy: -10.35387-0.07260j, varE: 1.30429\n",
      "step: 290, loss: 2.30254, mean energy: -10.83061-0.18295j, varE: 0.77552\n",
      "Best model saved at epoch 291 with best E=-10.92819+0.13078j, varE=0.73561\n",
      "step: 300, loss: 3.16379, mean energy: -10.56500+0.11280j, varE: 1.12440\n",
      "Best model saved at epoch 302 with best E=-10.94627+0.10391j, varE=1.25142\n",
      "Best model saved at epoch 303 with best E=-10.99899+0.03342j, varE=0.44462\n",
      "step: 310, loss: 2.98969, mean energy: -10.18161+0.03338j, varE: 1.26237\n",
      "step: 320, loss: -2.80283, mean energy: -10.22126-0.07708j, varE: 1.62080\n",
      "Best model saved at epoch 329 with best E=-11.15615-0.07761j, varE=0.79736\n",
      "step: 330, loss: -0.03873, mean energy: -10.89695+0.09150j, varE: 1.02877\n",
      "Best model saved at epoch 336 with best E=-11.18832-0.02233j, varE=0.47563\n",
      "step: 340, loss: -1.09917, mean energy: -11.12261-0.08950j, varE: 0.60826\n",
      "Best model saved at epoch 346 with best E=-11.21533-0.04831j, varE=0.52148\n",
      "Best model saved at epoch 347 with best E=-11.22162+0.03640j, varE=0.17883\n",
      "Best model saved at epoch 350 with best E=-11.23724+0.01042j, varE=0.42849\n",
      "step: 350, loss: 0.20475, mean energy: -11.23724+0.01042j, varE: 0.42849\n",
      "Best model saved at epoch 355 with best E=-11.26821-0.01901j, varE=0.24191\n",
      "Best model saved at epoch 359 with best E=-11.28491-0.00538j, varE=0.13054\n",
      "step: 360, loss: -1.11637, mean energy: -11.24824-0.03827j, varE: 0.22269\n",
      "Best model saved at epoch 361 with best E=-11.33324-0.05819j, varE=0.13647\n",
      "step: 370, loss: -1.26405, mean energy: -11.23125+0.01446j, varE: 0.21961\n",
      "Best model saved at epoch 371 with best E=-11.35323-0.01203j, varE=0.10111\n",
      "Best model saved at epoch 380 with best E=-11.35881-0.02791j, varE=0.52270\n",
      "step: 380, loss: 0.47495, mean energy: -11.35881-0.02791j, varE: 0.52270\n",
      "step: 390, loss: -1.19646, mean energy: -11.14421-0.05151j, varE: 0.37797\n",
      "step: 400, loss: -1.12408, mean energy: -11.11557-0.06918j, varE: 0.85991\n",
      "step: 410, loss: -0.11580, mean energy: -11.22298-0.03731j, varE: 0.68591\n",
      "Best model saved at epoch 420 with best E=-11.36112+0.02033j, varE=0.20888\n",
      "step: 420, loss: 0.44091, mean energy: -11.36112+0.02033j, varE: 0.20888\n",
      "step: 430, loss: 0.55046, mean energy: -11.27664-0.02489j, varE: 0.09490\n",
      "Best model saved at epoch 434 with best E=-11.37317-0.02014j, varE=0.14772\n",
      "Best model saved at epoch 439 with best E=-11.38520+0.01461j, varE=0.11200\n",
      "step: 440, loss: -0.08385, mean energy: -11.30811+0.00688j, varE: 0.02730\n",
      "Best model saved at epoch 450 with best E=-11.40731+0.02115j, varE=0.24439\n",
      "step: 450, loss: -1.51220, mean energy: -11.40731+0.02115j, varE: 0.24439\n",
      "step: 460, loss: 0.20381, mean energy: -11.33585+0.01053j, varE: 0.02113\n",
      "step: 470, loss: 0.04494, mean energy: -11.34195+0.00852j, varE: 0.04116\n",
      "step: 480, loss: -0.21869, mean energy: -11.27001-0.01195j, varE: 0.13825\n",
      "step: 490, loss: 6.07249, mean energy: -11.50944-0.23038j, varE: 5.57052\n",
      "Best model saved at epoch 500 with best E=-11.51463-0.11825j, varE=2.53561\n",
      "step: 500, loss: 1.83736, mean energy: -11.51463-0.11825j, varE: 2.53561\n",
      "Total time taken: 11.795\n"
     ]
    }
   ],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 57\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "nsteps=505\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.55,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1490fc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.53725, mean energy: 11.52415-0.00719j, varE: 1.48318\n",
      "step: 10, loss: -0.06060, mean energy: -0.73598+0.21279j, varE: 8.52583\n",
      "step: 20, loss: 3.58000, mean energy: -2.54576+0.03392j, varE: 6.39923\n",
      "step: 30, loss: -2.26369, mean energy: -5.11180-0.21194j, varE: 4.70692\n",
      "step: 40, loss: -4.99415, mean energy: -6.65871-0.05175j, varE: 4.42478\n",
      "step: 50, loss: 2.27335, mean energy: -7.88731-0.20993j, varE: 3.59857\n",
      "Best model saved at epoch 60 with best E=-9.16329+0.07193j, varE=1.87824\n",
      "step: 60, loss: -2.48755, mean energy: -9.16329+0.07193j, varE: 1.87824\n",
      "Best model saved at epoch 68 with best E=-9.86594-0.15083j, varE=1.19312\n",
      "step: 70, loss: -2.30797, mean energy: -9.76865+0.07089j, varE: 2.55179\n",
      "step: 80, loss: -1.75036, mean energy: -9.34098-0.11800j, varE: 1.63284\n",
      "Best model saved at epoch 87 with best E=-9.89533-0.02321j, varE=1.00647\n",
      "step: 90, loss: -1.82702, mean energy: -9.53723-0.13498j, varE: 4.12660\n",
      "step: 100, loss: -5.94459, mean energy: -9.47133-0.00580j, varE: 2.58655\n",
      "Best model saved at epoch 109 with best E=-9.92978+0.00040j, varE=1.43067\n",
      "Best model saved at epoch 110 with best E=-10.06542+0.10228j, varE=1.33623\n",
      "step: 110, loss: 0.97894, mean energy: -10.06542+0.10228j, varE: 1.33623\n",
      "Best model saved at epoch 118 with best E=-10.07930+0.24864j, varE=1.91582\n",
      "step: 120, loss: 4.64287, mean energy: -9.51024+0.18756j, varE: 2.46430\n",
      "Best model saved at epoch 123 with best E=-10.26862-0.10851j, varE=1.19817\n",
      "step: 130, loss: 0.32282, mean energy: -9.84001+0.10028j, varE: 2.55672\n",
      "step: 140, loss: 3.27416, mean energy: -10.05903-0.32850j, varE: 2.89462\n",
      "step: 150, loss: 1.23441, mean energy: -10.44569-0.14347j, varE: 2.03914\n",
      "Best model saved at epoch 155 with best E=-10.27685+0.01158j, varE=0.83535\n",
      "Best model saved at epoch 157 with best E=-10.38465+0.10514j, varE=1.14871\n",
      "Best model saved at epoch 159 with best E=-10.42877+0.10022j, varE=0.97459\n",
      "step: 160, loss: -0.73663, mean energy: -10.36417-0.09304j, varE: 1.46441\n",
      "Best model saved at epoch 161 with best E=-10.51325+0.15311j, varE=1.27704\n",
      "step: 170, loss: 1.00521, mean energy: -10.34654+0.06581j, varE: 1.02238\n",
      "step: 180, loss: 2.13647, mean energy: -10.39814+0.05360j, varE: 1.65164\n",
      "Best model saved at epoch 181 with best E=-10.62884-0.10629j, varE=0.90647\n",
      "Best model saved at epoch 184 with best E=-10.66088-0.02325j, varE=0.86691\n",
      "Best model saved at epoch 187 with best E=-10.77634-0.03079j, varE=0.76996\n",
      "step: 190, loss: -0.33031, mean energy: -10.68963+0.04616j, varE: 0.82040\n",
      "Best model saved at epoch 192 with best E=-10.78481-0.00680j, varE=0.49678\n",
      "Best model saved at epoch 196 with best E=-10.80763+0.12782j, varE=0.67845\n",
      "Best model saved at epoch 197 with best E=-10.89938+0.03282j, varE=0.60176\n",
      "step: 200, loss: 4.24632, mean energy: -10.60200-0.06326j, varE: 1.19967\n",
      "step: 210, loss: 4.06969, mean energy: -10.39771-0.09160j, varE: 2.46049\n",
      "step: 220, loss: -0.09005, mean energy: -9.89242+0.22431j, varE: 3.42389\n",
      "step: 230, loss: 4.67635, mean energy: -10.36855+0.01679j, varE: 1.38129\n",
      "step: 240, loss: -3.24972, mean energy: -7.14183-0.00421j, varE: 6.07811\n",
      "step: 250, loss: -4.15072, mean energy: -7.49550+0.24058j, varE: 4.92765\n",
      "step: 260, loss: -4.18061, mean energy: -9.71089-0.06100j, varE: 2.15830\n",
      "step: 270, loss: -2.12872, mean energy: -10.41361+0.05454j, varE: 1.24637\n",
      "step: 280, loss: 1.57931, mean energy: -10.35387-0.07260j, varE: 1.30429\n",
      "step: 290, loss: 2.30254, mean energy: -10.83061-0.18295j, varE: 0.77552\n",
      "Best model saved at epoch 291 with best E=-10.92819+0.13078j, varE=0.73561\n",
      "step: 300, loss: 3.16379, mean energy: -10.56500+0.11280j, varE: 1.12440\n",
      "Best model saved at epoch 302 with best E=-10.94627+0.10391j, varE=1.25142\n",
      "Best model saved at epoch 303 with best E=-10.99899+0.03342j, varE=0.44462\n",
      "step: 310, loss: 2.98969, mean energy: -10.18161+0.03338j, varE: 1.26237\n",
      "step: 320, loss: -2.80283, mean energy: -10.22126-0.07708j, varE: 1.62080\n",
      "Best model saved at epoch 329 with best E=-11.15615-0.07761j, varE=0.79736\n",
      "step: 330, loss: -0.03873, mean energy: -10.89695+0.09150j, varE: 1.02877\n",
      "Best model saved at epoch 336 with best E=-11.18832-0.02233j, varE=0.47563\n",
      "step: 340, loss: -1.09917, mean energy: -11.12261-0.08950j, varE: 0.60826\n",
      "Best model saved at epoch 346 with best E=-11.21533-0.04831j, varE=0.52148\n",
      "Best model saved at epoch 347 with best E=-11.22162+0.03640j, varE=0.17883\n",
      "Best model saved at epoch 350 with best E=-11.23724+0.01042j, varE=0.42849\n",
      "step: 350, loss: 0.20475, mean energy: -11.23724+0.01042j, varE: 0.42849\n",
      "Best model saved at epoch 355 with best E=-11.26821-0.01901j, varE=0.24191\n",
      "Best model saved at epoch 359 with best E=-11.28491-0.00538j, varE=0.13054\n",
      "step: 360, loss: -1.11637, mean energy: -11.24824-0.03827j, varE: 0.22269\n",
      "Best model saved at epoch 361 with best E=-11.33324-0.05819j, varE=0.13647\n",
      "step: 370, loss: -1.26405, mean energy: -11.23125+0.01446j, varE: 0.21961\n",
      "Best model saved at epoch 371 with best E=-11.35323-0.01203j, varE=0.10111\n",
      "Best model saved at epoch 380 with best E=-11.35881-0.02791j, varE=0.52270\n",
      "step: 380, loss: 0.47495, mean energy: -11.35881-0.02791j, varE: 0.52270\n",
      "step: 390, loss: -1.19646, mean energy: -11.14421-0.05151j, varE: 0.37797\n",
      "step: 400, loss: -1.12408, mean energy: -11.11557-0.06918j, varE: 0.85991\n",
      "step: 410, loss: -0.11580, mean energy: -11.22298-0.03731j, varE: 0.68591\n",
      "Best model saved at epoch 420 with best E=-11.36112+0.02033j, varE=0.20888\n",
      "step: 420, loss: 0.44091, mean energy: -11.36112+0.02033j, varE: 0.20888\n",
      "step: 430, loss: 0.55046, mean energy: -11.27664-0.02489j, varE: 0.09490\n",
      "Best model saved at epoch 434 with best E=-11.37317-0.02014j, varE=0.14772\n",
      "Best model saved at epoch 439 with best E=-11.38520+0.01461j, varE=0.11200\n",
      "step: 440, loss: -0.08385, mean energy: -11.30811+0.00688j, varE: 0.02730\n",
      "Best model saved at epoch 450 with best E=-11.40731+0.02115j, varE=0.24439\n",
      "step: 450, loss: -1.51220, mean energy: -11.40731+0.02115j, varE: 0.24439\n",
      "step: 460, loss: 0.20381, mean energy: -11.33585+0.01053j, varE: 0.02113\n",
      "step: 470, loss: 0.04494, mean energy: -11.34195+0.00852j, varE: 0.04116\n",
      "step: 480, loss: -0.21869, mean energy: -11.27001-0.01195j, varE: 0.13825\n",
      "step: 490, loss: 6.07249, mean energy: -11.50944-0.23038j, varE: 5.57052\n",
      "step: 500, loss: 1.83736, mean energy: -11.51463-0.11825j, varE: 2.53561\n",
      "step: 510, loss: -6.01472, mean energy: -10.99330-0.27203j, varE: 8.61026\n",
      "step: 520, loss: -2.36514, mean energy: -10.53685+0.00951j, varE: 0.99763\n",
      "step: 530, loss: 2.24305, mean energy: -10.61672+0.09806j, varE: 1.48178\n",
      "step: 540, loss: -4.31636, mean energy: -10.74482+0.12611j, varE: 1.14867\n",
      "step: 550, loss: 2.11427, mean energy: -11.15729-0.00806j, varE: 0.27223\n",
      "Total time taken: 22.013\n"
     ]
    }
   ],
   "source": [
    "#DIFFERENT VAR_TOL, LONGER TRAINING: RESULT NOT AS GOOD\n",
    "cell_type = 'HypGRU'\n",
    "hidden_units = 57\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "nsteps=551\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2J3_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=2.0,\n",
    "                          J1_ = J1, J2_ = J2, J3_ = J3, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = '../results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4013f823-0d6b-45d2-9981-9d7fb64dd1f3",
   "metadata": {},
   "source": [
    "# 1D J1=1.0, J2=0.0: Training with no gradient clipping\n",
    "\n",
    "This notebook is part of the work arXiv:2505.22083 (https://arxiv.org/abs/2505.22083), \"Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz\". Code written by HLD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9abff75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 12:23:55.337001: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../utility')\n",
    "from j1j2_hyprnn_train_loop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fd866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_exact = -21.97211\n",
    "syssize = 50\n",
    "nssamples = 50\n",
    "J1 = 1.0\n",
    "J2 = 0.0\n",
    "\n",
    "var_tol = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f89e",
   "metadata": {},
   "source": [
    "# EuclGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2e873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_eucl_wf at 0x18fc52f10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 75\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "wf_egru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02bf522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -0.52756, mean energy: 12.05817+0.07567j, varE: 0.18605\n",
      "step: 10, loss: -1.22160, mean energy: -2.78196+0.06689j, varE: 10.03769\n",
      "step: 20, loss: -0.96057, mean energy: -8.29097-0.11743j, varE: 9.35433\n",
      "step: 30, loss: 11.71136, mean energy: -13.17259+0.42007j, varE: 9.67081\n",
      "step: 40, loss: 5.72153, mean energy: -14.66930+0.17066j, varE: 8.04487\n",
      "step: 50, loss: -10.84676, mean energy: -14.94230+0.26080j, varE: 9.93237\n",
      "step: 60, loss: -0.20100, mean energy: -17.54974-0.08438j, varE: 3.56603\n",
      "step: 70, loss: 4.54918, mean energy: -17.97792-0.00926j, varE: 4.07279\n",
      "step: 80, loss: 2.58440, mean energy: -18.83425+0.02277j, varE: 3.55651\n",
      "step: 90, loss: 9.19978, mean energy: -19.27993-0.16158j, varE: 3.80460\n",
      "step: 100, loss: -2.74994, mean energy: -19.88862+0.17263j, varE: 2.23526\n",
      "step: 110, loss: -3.81100, mean energy: -20.01098-0.11363j, varE: 3.07779\n",
      "Best model saved at epoch 120 with best E=-20.27645+0.03896j, varE=0.69443\n",
      "step: 120, loss: 3.35526, mean energy: -20.27645+0.03896j, varE: 0.69443\n",
      "Best model saved at epoch 126 with best E=-20.68209-0.07162j, varE=0.75991\n",
      "Best model saved at epoch 128 with best E=-20.83366+0.00966j, varE=0.57233\n",
      "step: 130, loss: 2.71082, mean energy: -20.74895+0.01403j, varE: 1.00319\n",
      "step: 140, loss: -2.40344, mean energy: -20.31912-0.04292j, varE: 9.72905\n",
      "Best model saved at epoch 141 with best E=-20.89458+0.02107j, varE=0.62687\n",
      "step: 150, loss: -1.16550, mean energy: -20.89049-0.13185j, varE: 0.82025\n",
      "step: 160, loss: 1.58771, mean energy: -20.71530+0.12882j, varE: 1.80304\n",
      "Best model saved at epoch 163 with best E=-20.95982-0.06094j, varE=0.69540\n",
      "step: 170, loss: 0.30862, mean energy: -20.76951-0.00315j, varE: 1.03015\n",
      "step: 180, loss: -4.11533, mean energy: -20.33042+0.15301j, varE: 1.23084\n",
      "step: 190, loss: 0.37985, mean energy: -20.88494-0.07048j, varE: 0.46025\n",
      "Best model saved at epoch 193 with best E=-21.00127-0.08396j, varE=0.51518\n",
      "Best model saved at epoch 200 with best E=-21.10571-0.07319j, varE=0.23234\n",
      "step: 200, loss: -1.88416, mean energy: -21.10571-0.07319j, varE: 0.23234\n",
      "Best model saved at epoch 201 with best E=-21.12822-0.03049j, varE=0.42111\n",
      "Best model saved at epoch 209 with best E=-21.16462-0.06770j, varE=0.50077\n",
      "step: 210, loss: -1.55014, mean energy: -21.11168-0.02331j, varE: 0.66226\n",
      "step: 220, loss: -2.29968, mean energy: -20.94423+0.03049j, varE: 0.53733\n",
      "Best model saved at epoch 228 with best E=-21.23051+0.03176j, varE=0.55767\n",
      "step: 230, loss: -3.83325, mean energy: -21.03493+0.02651j, varE: 0.68234\n",
      "step: 240, loss: 1.83737, mean energy: -20.81254-0.09178j, varE: 1.10937\n",
      "step: 250, loss: -0.19946, mean energy: -21.12249-0.00954j, varE: 0.34709\n",
      "step: 260, loss: 11.44421, mean energy: -17.97367-0.13386j, varE: 7.11198\n",
      "step: 270, loss: -10.41925, mean energy: -20.23080+0.38647j, varE: 7.44750\n",
      "step: 280, loss: -2.55188, mean energy: -19.97656-0.10465j, varE: 3.64806\n",
      "step: 290, loss: -0.27014, mean energy: -20.65868-0.09805j, varE: 1.24273\n",
      "step: 300, loss: -0.98422, mean energy: -20.89248+0.00209j, varE: 0.66094\n",
      "step: 310, loss: -0.15140, mean energy: -21.11923+0.05809j, varE: 0.95028\n",
      "step: 320, loss: 1.27493, mean energy: -21.06166-0.13024j, varE: 4.86719\n",
      "step: 330, loss: -3.17612, mean energy: -21.02168-0.10346j, varE: 0.61667\n",
      "Best model saved at epoch 335 with best E=-21.27666-0.02738j, varE=0.76269\n",
      "step: 340, loss: 2.63605, mean energy: -21.01480-0.09000j, varE: 0.55394\n",
      "step: 350, loss: -0.33609, mean energy: -21.10397-0.07252j, varE: 0.81571\n",
      "step: 360, loss: 0.26947, mean energy: -20.94083-0.00162j, varE: 0.69144\n",
      "Best model saved at epoch 364 with best E=-21.29772-0.02554j, varE=0.38439\n",
      "step: 370, loss: 0.33551, mean energy: -21.03492-0.01554j, varE: 0.96740\n",
      "Best model saved at epoch 375 with best E=-21.34981+0.00375j, varE=0.46033\n",
      "Best model saved at epoch 378 with best E=-21.36921+0.06424j, varE=0.43762\n",
      "Best model saved at epoch 379 with best E=-21.39652+0.14875j, varE=0.55601\n",
      "step: 380, loss: 1.21832, mean energy: -21.25142+0.02158j, varE: 1.45224\n",
      "step: 390, loss: 0.73712, mean energy: -21.32963-0.03551j, varE: 0.35631\n",
      "step: 400, loss: -1.46216, mean energy: -21.17025-0.01854j, varE: 0.44660\n",
      "Total time taken: 2.272\n"
     ]
    }
   ],
   "source": [
    "nsteps = 401\n",
    "start = time.time()\n",
    "\n",
    "mE, vE = run_J1J2(wf=wf_egru, numsteps=nsteps, systemsize=syssize, var_tol=0.8, J1_  = J1, \n",
    "                   J2_ = J2, Marshall_sign = True, \n",
    "                  numsamples = nssamples, learningrate = 1e-2, seed = 111, fname = 'results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587abf4",
   "metadata": {},
   "source": [
    "# HypGRU\n",
    "\n",
    "## units = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20eb48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_hyp_wf at 0x7fc71052eee0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 60\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "wf_hgru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd287c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -0.92902, mean energy: 11.82525-0.35288j, varE: 1.14977\n",
      "step: 10, loss: -5.76703, mean energy: -4.78317+0.60246j, varE: 15.23068\n",
      "step: 20, loss: -5.80670, mean energy: -7.77651-0.21586j, varE: 15.94191\n",
      "step: 30, loss: -4.15848, mean energy: -8.95847-0.26542j, varE: 12.13764\n",
      "step: 40, loss: -10.40121, mean energy: -11.17773+0.04611j, varE: 16.20992\n",
      "step: 50, loss: -11.57700, mean energy: -13.41514-0.30384j, varE: 9.32067\n",
      "step: 60, loss: -7.80190, mean energy: -15.44880+0.09891j, varE: 7.28249\n",
      "step: 70, loss: -10.93118, mean energy: -16.21392+0.14874j, varE: 11.25738\n",
      "step: 80, loss: -6.60855, mean energy: -17.06080-0.01353j, varE: 7.82282\n",
      "step: 90, loss: 1.98547, mean energy: -17.58457-0.00363j, varE: 6.16939\n",
      "step: 100, loss: -4.03529, mean energy: -18.82587-0.14108j, varE: 6.80202\n",
      "step: 110, loss: 7.24835, mean energy: -17.43170-0.01387j, varE: 5.71105\n",
      "step: 120, loss: 0.70491, mean energy: -18.84301+0.04069j, varE: 2.47333\n",
      "Best model saved at epoch 129 with best E=-19.05481-0.09160j, varE=1.88393\n",
      "step: 130, loss: 1.12407, mean energy: -18.42691-0.24969j, varE: 15.29102\n",
      "step: 140, loss: 0.44328, mean energy: -18.91308+0.06247j, varE: 3.44209\n",
      "step: 150, loss: -4.98203, mean energy: -19.30000-0.05644j, varE: 3.10877\n",
      "Best model saved at epoch 153 with best E=-19.43510+0.19532j, varE=1.82846\n",
      "step: 160, loss: 1.99124, mean energy: -19.32937-0.04815j, varE: 2.42673\n",
      "Best model saved at epoch 168 with best E=-19.69512+0.05089j, varE=1.61909\n",
      "step: 170, loss: 1.07005, mean energy: -19.71861-0.00343j, varE: 2.90045\n",
      "Best model saved at epoch 171 with best E=-19.82374+0.05669j, varE=1.26225\n",
      "Best model saved at epoch 176 with best E=-19.86814-0.07551j, varE=1.76385\n",
      "step: 180, loss: 5.20511, mean energy: -19.79787-0.07325j, varE: 2.57783\n",
      "Best model saved at epoch 189 with best E=-20.00751+0.12404j, varE=1.58611\n",
      "step: 190, loss: 2.55679, mean energy: -19.64399+0.01630j, varE: 2.33871\n",
      "step: 200, loss: -0.52571, mean energy: -19.80883+0.10240j, varE: 1.67014\n",
      "Best model saved at epoch 205 with best E=-20.01567+0.10166j, varE=1.97171\n",
      "step: 210, loss: -2.59750, mean energy: -19.94830+0.11472j, varE: 1.55270\n",
      "step: 220, loss: -4.51199, mean energy: -19.42896-0.10368j, varE: 2.95944\n",
      "Best model saved at epoch 230 with best E=-20.20665-0.33481j, varE=1.64087\n",
      "step: 230, loss: -1.48779, mean energy: -20.20665-0.33481j, varE: 1.64087\n",
      "step: 240, loss: 4.07736, mean energy: -19.83913-0.08623j, varE: 1.55256\n",
      "Best model saved at epoch 243 with best E=-20.25976+0.11904j, varE=1.61933\n",
      "step: 250, loss: 2.18314, mean energy: -19.90201-0.04924j, varE: 2.04658\n",
      "Best model saved at epoch 255 with best E=-20.42947+0.09855j, varE=1.50022\n",
      "step: 260, loss: 1.36642, mean energy: -20.26679-0.09013j, varE: 1.54995\n",
      "step: 270, loss: 2.89072, mean energy: -20.23336+0.07289j, varE: 1.24681\n",
      "step: 280, loss: -1.90195, mean energy: -20.07137+0.18086j, varE: 1.86966\n",
      "Best model saved at epoch 282 with best E=-20.46808-0.02091j, varE=1.51445\n",
      "Best model saved at epoch 289 with best E=-20.52968-0.00198j, varE=0.83366\n",
      "step: 290, loss: 0.50000, mean energy: -20.38828-0.03492j, varE: 1.01543\n",
      "Best model saved at epoch 295 with best E=-20.53500+0.00423j, varE=0.91652\n",
      "step: 300, loss: -0.22284, mean energy: -20.12764+0.10685j, varE: 2.08036\n",
      "step: 310, loss: 0.24072, mean energy: -20.34549-0.00833j, varE: 1.39526\n",
      "step: 320, loss: -1.69736, mean energy: -20.33983+0.04030j, varE: 1.51625\n",
      "step: 330, loss: -2.52951, mean energy: -20.31422+0.04960j, varE: 0.94293\n",
      "Best model saved at epoch 331 with best E=-20.57938-0.02067j, varE=0.72928\n",
      "Best model saved at epoch 336 with best E=-20.65586+0.10772j, varE=0.71323\n",
      "step: 340, loss: -0.07410, mean energy: -20.63293-0.02740j, varE: 0.40256\n",
      "step: 350, loss: -9.41026, mean energy: -14.44553+0.38947j, varE: 5.42181\n",
      "step: 360, loss: -2.41814, mean energy: -17.68977+0.18692j, varE: 7.69574\n",
      "step: 370, loss: 0.71231, mean energy: -18.74210+0.04488j, varE: 4.06992\n",
      "step: 380, loss: 1.84196, mean energy: -19.71981-0.11607j, varE: 2.28375\n",
      "step: 390, loss: 3.64291, mean energy: -19.45757+0.17456j, varE: 3.21800\n",
      "step: 400, loss: 3.50449, mean energy: -19.81083-0.12668j, varE: 1.96369\n",
      "step: 410, loss: 1.92398, mean energy: -20.42336-0.27568j, varE: 2.31321\n",
      "step: 420, loss: -1.19229, mean energy: -20.40623-0.12235j, varE: 1.30559\n",
      "step: 430, loss: -0.68488, mean energy: -20.48614-0.03590j, varE: 1.18295\n",
      "step: 440, loss: -0.56537, mean energy: -20.64171+0.00218j, varE: 0.53119\n",
      "step: 450, loss: -2.38199, mean energy: -20.42659+0.03953j, varE: 1.52921\n",
      "Total time taken: 51139.579051971436\n"
     ]
    }
   ],
   "source": [
    "nsteps=451\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=var_tol,\n",
    "                          J1_ = J1, J2_ = J2, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = 'results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {duration}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc1e0b",
   "metadata": {},
   "source": [
    "## units = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0197e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_hyp_wf at 0x3618633d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 75\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "wf_hgru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933406d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -0.33630, mean energy: 10.60771+0.33771j, varE: 2.93050\n",
      "step: 10, loss: -8.28863, mean energy: -2.48768+0.16763j, varE: 12.25800\n",
      "step: 20, loss: -9.32207, mean energy: -4.90466-0.56490j, varE: 10.11232\n",
      "step: 30, loss: -6.20851, mean energy: -9.18855+0.43459j, varE: 10.27863\n",
      "step: 40, loss: -6.60107, mean energy: -11.02464-0.42387j, varE: 15.86403\n",
      "step: 50, loss: 3.70819, mean energy: -12.81458-0.02721j, varE: 11.17354\n",
      "step: 60, loss: -7.89203, mean energy: -14.05959+0.05277j, varE: 8.36537\n",
      "step: 70, loss: 23.16888, mean energy: -14.52351-0.17990j, varE: 7.17576\n",
      "step: 80, loss: -7.90074, mean energy: -15.65344+0.00921j, varE: 7.43156\n",
      "step: 90, loss: 9.57071, mean energy: -16.41151-0.18655j, varE: 10.00795\n",
      "step: 100, loss: 16.97118, mean energy: -15.96441+0.09659j, varE: 8.80699\n",
      "step: 110, loss: 6.87543, mean energy: -17.07543-0.24391j, varE: 5.13720\n",
      "step: 120, loss: -5.08092, mean energy: -16.36385-0.17693j, varE: 7.21516\n",
      "step: 130, loss: 2.48688, mean energy: -17.44219+0.04423j, varE: 4.48514\n",
      "step: 140, loss: 8.81354, mean energy: -18.16514-0.00359j, varE: 5.59377\n",
      "step: 150, loss: -21.08063, mean energy: -18.10393+0.22320j, varE: 4.92235\n",
      "step: 160, loss: 22.31255, mean energy: -17.59403+0.35540j, varE: 6.97133\n",
      "step: 170, loss: -26.98737, mean energy: -17.89456-0.35529j, varE: 17.15449\n",
      "step: 180, loss: 19.86490, mean energy: -18.27134+0.10858j, varE: 6.87471\n",
      "step: 190, loss: 2.51482, mean energy: -18.94075-0.08495j, varE: 2.64178\n",
      "step: 200, loss: 1.01370, mean energy: -19.21786-0.04041j, varE: 3.41568\n",
      "Best model saved at epoch 201 with best E=-18.95063+0.07935j, varE=1.86754\n",
      "Best model saved at epoch 204 with best E=-19.44966-0.14906j, varE=1.58802\n",
      "step: 210, loss: -6.51033, mean energy: -19.11892+0.23552j, varE: 3.57253\n",
      "step: 220, loss: 14.35298, mean energy: -17.88182-0.25881j, varE: 5.90903\n",
      "step: 230, loss: 68.65428, mean energy: -18.08132-0.27240j, varE: 10.82183\n",
      "step: 240, loss: -2.25243, mean energy: -18.50455-0.22350j, varE: 4.04771\n",
      "step: 250, loss: -7.51677, mean energy: -19.15788-0.01635j, varE: 2.91226\n",
      "step: 260, loss: -2.54434, mean energy: -19.04627-0.08912j, varE: 3.65200\n",
      "step: 270, loss: 6.23764, mean energy: -19.21986-0.01635j, varE: 3.04474\n",
      "step: 280, loss: -8.05002, mean energy: -19.02312-0.15041j, varE: 2.54375\n",
      "Best model saved at epoch 284 with best E=-19.49553-0.07821j, varE=1.27142\n",
      "Best model saved at epoch 285 with best E=-19.56777-0.15805j, varE=1.83423\n",
      "Best model saved at epoch 290 with best E=-19.58563-0.08673j, varE=0.98525\n",
      "step: 290, loss: 6.26152, mean energy: -19.58563-0.08673j, varE: 0.98525\n",
      "Best model saved at epoch 296 with best E=-19.73871-0.10691j, varE=1.28066\n",
      "Best model saved at epoch 297 with best E=-19.74401-0.03246j, varE=1.34871\n",
      "step: 300, loss: 8.74225, mean energy: -19.38239-0.09918j, varE: 2.22135\n",
      "step: 310, loss: -0.29883, mean energy: -19.26816-0.53716j, varE: 3.01021\n",
      "step: 320, loss: -9.64719, mean energy: -19.25180-0.09128j, varE: 3.94448\n",
      "step: 330, loss: -0.24928, mean energy: -19.48838-0.02317j, varE: 2.74560\n",
      "Best model saved at epoch 337 with best E=-19.85559+0.04388j, varE=1.91539\n",
      "step: 340, loss: -26.42261, mean energy: -19.04009-0.30911j, varE: 4.00725\n",
      "step: 350, loss: 19.84486, mean energy: -19.57982-0.28681j, varE: 4.23751\n",
      "step: 360, loss: -18.43979, mean energy: -19.31426-0.14209j, varE: 3.77472\n",
      "Best model saved at epoch 368 with best E=-19.90597-0.08361j, varE=1.59766\n",
      "Best model saved at epoch 369 with best E=-20.08616-0.00672j, varE=1.10285\n",
      "step: 370, loss: 9.86238, mean energy: -19.94405-0.11468j, varE: 1.02806\n",
      "Best model saved at epoch 375 with best E=-20.14759-0.03702j, varE=0.99091\n",
      "step: 380, loss: 5.54141, mean energy: -19.93696-0.09356j, varE: 2.39395\n",
      "Best model saved at epoch 381 with best E=-20.22957-0.00621j, varE=1.99874\n",
      "step: 390, loss: -18.12254, mean energy: -19.85915+0.04654j, varE: 4.16528\n",
      "step: 400, loss: 4.30945, mean energy: -19.70135+0.08424j, varE: 1.83144\n",
      "step: 410, loss: -9.59848, mean energy: -19.71976-0.14708j, varE: 2.67154\n",
      "step: 420, loss: -6.83386, mean energy: -19.82146-0.08832j, varE: 2.13710\n",
      "step: 430, loss: -0.47870, mean energy: -19.71032+0.08497j, varE: 3.08349\n",
      "step: 440, loss: -3.00240, mean energy: -19.94789-0.12167j, varE: 0.94940\n",
      "Best model saved at epoch 447 with best E=-20.31904+0.01721j, varE=0.88683\n",
      "step: 450, loss: -0.73540, mean energy: -19.73909-0.15159j, varE: 2.84173\n",
      "step: 460, loss: 2.12451, mean energy: -20.25599-0.13493j, varE: 1.08425\n",
      "Best model saved at epoch 463 with best E=-20.43543-0.11893j, varE=1.32703\n",
      "step: 470, loss: -9.55374, mean energy: -19.34555-0.09057j, varE: 3.33874\n",
      "step: 480, loss: 0.35519, mean energy: -20.11423-0.25185j, varE: 3.72001\n",
      "step: 490, loss: -1.11978, mean energy: -20.04930+0.01591j, varE: 1.22027\n",
      "step: 500, loss: 2.54416, mean energy: -20.34229-0.21017j, varE: 5.27760\n",
      "step: 510, loss: -1.28636, mean energy: -19.59052+0.05375j, varE: 3.09836\n",
      "step: 520, loss: -7.47260, mean energy: -19.94855+0.30771j, varE: 2.94686\n",
      "step: 530, loss: 3.61948, mean energy: -20.19645+0.18388j, varE: 1.13674\n",
      "step: 540, loss: 5.09933, mean energy: -20.10642-0.04526j, varE: 1.38545\n",
      "step: 550, loss: -2.87930, mean energy: -20.20737+0.15438j, varE: 1.20626\n",
      "Total time taken: 79585.098279953\n"
     ]
    }
   ],
   "source": [
    "nsteps=551\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=var_tol,\n",
    "                          J1_ = J1, J2_ = J2, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = 'results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {duration}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

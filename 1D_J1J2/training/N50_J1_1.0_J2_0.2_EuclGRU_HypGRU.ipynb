{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9abff75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 02:00:07.294839: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../utility')\n",
    "from j1j2_hyprnn_train_loop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fd866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_exact = -20.31498\n",
    "syssize = 50\n",
    "nssamples = 50\n",
    "J1 = 1.0\n",
    "J2 = 0.2\n",
    "nsteps = 401\n",
    "var_tol = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f89e",
   "metadata": {},
   "source": [
    "# EuclGRU\n",
    "\n",
    "## units =75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6ddbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_eucl_wf at 0x7fcfc1607130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 75\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "wf_egru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51370d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -0.73938, mean energy: 14.45013+0.08308j, varE: 0.32071\n",
      "step: 10, loss: 5.41662, mean energy: -2.89580-0.12156j, varE: 11.49734\n",
      "step: 20, loss: -5.64630, mean energy: -8.21082+0.01800j, varE: 7.70279\n",
      "step: 30, loss: -5.33572, mean energy: -13.57169+0.06622j, varE: 5.35775\n",
      "step: 40, loss: 5.07106, mean energy: -12.75765-0.04168j, varE: 5.66270\n",
      "step: 50, loss: 1.40079, mean energy: -14.72131-0.00469j, varE: 4.27085\n",
      "step: 60, loss: -0.24324, mean energy: -16.30170-0.08738j, varE: 3.41978\n",
      "Best model saved at epoch 69 with best E=-16.10290-0.00795j, varE=1.98264\n",
      "step: 70, loss: 3.44768, mean energy: -15.98728+0.01997j, varE: 6.09021\n",
      "step: 80, loss: -0.85826, mean energy: -16.19547+0.13528j, varE: 2.83049\n",
      "step: 90, loss: -5.96407, mean energy: -16.32579-0.05747j, varE: 3.17805\n",
      "Best model saved at epoch 92 with best E=-17.09813+0.15045j, varE=1.76827\n",
      "step: 100, loss: 5.64262, mean energy: -17.19268-0.17654j, varE: 2.10210\n",
      "step: 110, loss: 3.17433, mean energy: -17.64728+0.10422j, varE: 2.04547\n",
      "Best model saved at epoch 120 with best E=-17.47109-0.05119j, varE=1.63580\n",
      "step: 120, loss: 3.07323, mean energy: -17.47109-0.05119j, varE: 1.63580\n",
      "step: 130, loss: 1.99409, mean energy: -2.83021-0.05216j, varE: 15.02181\n",
      "step: 140, loss: 1.59473, mean energy: -4.33212-0.04532j, varE: 4.75057\n",
      "step: 150, loss: -4.79151, mean energy: -5.00002-0.08935j, varE: 6.31025\n",
      "step: 160, loss: -5.61088, mean energy: -8.27056-0.10533j, varE: 4.26268\n",
      "step: 170, loss: 1.14433, mean energy: -7.51616-0.02543j, varE: 0.96236\n",
      "step: 180, loss: -0.17644, mean energy: -10.04060-0.01039j, varE: 0.00853\n",
      "step: 190, loss: -0.36012, mean energy: -9.97004-0.00472j, varE: 0.06717\n",
      "step: 200, loss: -3.15258, mean energy: -9.32389-0.00672j, varE: 1.05441\n",
      "step: 210, loss: 6.55783, mean energy: -9.66681-0.49358j, varE: 8.46970\n",
      "step: 220, loss: -6.91040, mean energy: -10.42564+0.61642j, varE: 27.34532\n",
      "step: 230, loss: -1.47613, mean energy: -11.02709+0.35366j, varE: 10.09239\n",
      "step: 240, loss: -0.77403, mean energy: -10.78501-0.05604j, varE: 1.53048\n",
      "step: 250, loss: 2.68451, mean energy: -11.13664-0.07079j, varE: 1.30768\n",
      "step: 260, loss: 0.86232, mean energy: -11.25307-0.00615j, varE: 1.50497\n",
      "step: 270, loss: -0.16669, mean energy: -11.26019+0.17622j, varE: 3.32025\n",
      "step: 280, loss: -2.52944, mean energy: -10.95912+0.06714j, varE: 0.89337\n",
      "step: 290, loss: 0.73175, mean energy: -10.97785-0.02539j, varE: 1.03048\n",
      "step: 300, loss: 1.57491, mean energy: -10.51008+0.18216j, varE: 3.95961\n",
      "step: 310, loss: -1.25402, mean energy: -9.99625+0.02762j, varE: 1.31957\n",
      "step: 320, loss: 1.28998, mean energy: -10.12837-0.06249j, varE: 0.38262\n",
      "step: 330, loss: -0.19638, mean energy: -10.02953+0.00767j, varE: 0.06632\n",
      "step: 340, loss: -0.04618, mean energy: -10.10902-0.00269j, varE: 0.00191\n",
      "step: 350, loss: 0.82022, mean energy: -10.67675-0.11580j, varE: 1.59933\n",
      "step: 360, loss: -1.10254, mean energy: -10.68059-0.08984j, varE: 0.97699\n",
      "step: 370, loss: -0.69057, mean energy: -11.04317+0.07674j, varE: 1.26664\n",
      "step: 380, loss: 2.28055, mean energy: -11.18876+0.29371j, varE: 7.92364\n",
      "step: 390, loss: -0.66701, mean energy: -10.92045-0.13677j, varE: 0.88624\n",
      "step: 400, loss: 0.16123, mean energy: -10.96602-0.08050j, varE: 0.41357\n",
      "step: 410, loss: 2.28332, mean energy: -11.51518+0.09759j, varE: 3.88395\n",
      "step: 420, loss: 4.38757, mean energy: -11.10962-0.23355j, varE: 2.90564\n",
      "step: 430, loss: -1.59489, mean energy: -11.25870+0.01094j, varE: 0.67791\n",
      "step: 440, loss: -4.49393, mean energy: -11.05826+0.06032j, varE: 1.37436\n",
      "step: 450, loss: 1.10723, mean energy: -11.02454-0.05715j, varE: 0.65280\n",
      "Total time taken: 2.927\n"
     ]
    }
   ],
   "source": [
    "nsteps = 451\n",
    "start = time.time()\n",
    "\n",
    "mE, vE = run_J1J2(wf=wf_egru, numsteps=nsteps, systemsize=syssize, var_tol=2.0, J1_  = J1, \n",
    "                   J2_ = J2, Marshall_sign = True, \n",
    "                  numsamples = nssamples, learningrate = 1e-2, seed = 111, fname = 'results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0191e",
   "metadata": {},
   "source": [
    "## units =70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35ac622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_eucl_wf at 0x7fec49db66a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'EuclGRU'\n",
    "hidden_units = 70\n",
    "wf_egru = rnn_eucl_wf(syssize, cell_type, hidden_units)\n",
    "wf_egru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d736bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.28488, mean energy: 14.35143+0.11622j, varE: 0.57657\n",
      "step: 10, loss: 1.91219, mean energy: -3.26222-0.02600j, varE: 11.30628\n",
      "step: 20, loss: 5.80392, mean energy: -8.31789-0.34554j, varE: 8.58447\n",
      "step: 30, loss: -6.45927, mean energy: -12.00419-0.04883j, varE: 6.00318\n",
      "step: 40, loss: -5.28076, mean energy: -14.72082+0.10151j, varE: 5.24902\n",
      "step: 50, loss: -0.11549, mean energy: -13.97637+0.10396j, varE: 6.82538\n",
      "step: 60, loss: -0.51025, mean energy: -15.52815-0.08350j, varE: 4.45327\n",
      "step: 70, loss: -0.23318, mean energy: -15.72362+0.12796j, varE: 5.38781\n",
      "step: 80, loss: 0.69572, mean energy: -15.88345+0.05785j, varE: 3.37501\n",
      "step: 90, loss: 0.75294, mean energy: -16.44968-0.14079j, varE: 4.03999\n",
      "step: 100, loss: 2.89372, mean energy: -17.44619+0.02746j, varE: 3.08669\n",
      "Best model saved at epoch 110 with best E=-17.49947+0.01536j, varE=0.87494\n",
      "step: 110, loss: 0.12187, mean energy: -17.49947+0.01536j, varE: 0.87494\n",
      "step: 120, loss: -1.87341, mean energy: -16.73739-0.10743j, varE: 2.66742\n",
      "Best model saved at epoch 124 with best E=-17.51038-0.07315j, varE=0.88438\n",
      "step: 130, loss: 0.33902, mean energy: -17.04362+0.17462j, varE: 2.42248\n",
      "step: 140, loss: -2.94516, mean energy: -17.08446-0.11667j, varE: 2.10635\n",
      "step: 150, loss: -2.56282, mean energy: -17.38928-0.22362j, varE: 2.25060\n",
      "step: 160, loss: -0.74963, mean energy: -17.32598+0.12411j, varE: 1.17593\n",
      "step: 170, loss: 4.64301, mean energy: -17.72268-0.14209j, varE: 4.08741\n",
      "step: 180, loss: 2.36179, mean energy: -16.97338-0.08053j, varE: 2.22729\n",
      "step: 190, loss: 0.90067, mean energy: -17.30495+0.04045j, varE: 3.59925\n",
      "step: 200, loss: 6.70244, mean energy: -18.14290-0.02842j, varE: 1.32523\n",
      "step: 210, loss: -8.60086, mean energy: -6.65077-0.07381j, varE: 13.06766\n",
      "step: 220, loss: -2.19753, mean energy: -12.81126+0.11854j, varE: 22.74144\n",
      "step: 230, loss: 2.16432, mean energy: -14.88109+0.05178j, varE: 4.32219\n",
      "step: 240, loss: -0.09808, mean energy: -16.49729+0.39827j, varE: 11.04153\n",
      "step: 250, loss: -1.40714, mean energy: -17.95883+0.01455j, varE: 1.78400\n",
      "Best model saved at epoch 256 with best E=-18.13951-0.10752j, varE=0.97705\n",
      "step: 260, loss: -1.49832, mean energy: -18.15174+0.06232j, varE: 2.83694\n",
      "Best model saved at epoch 266 with best E=-18.54756-0.00567j, varE=0.91456\n",
      "step: 270, loss: 2.01465, mean energy: -18.18365-0.13895j, varE: 1.40309\n",
      "step: 280, loss: 3.00450, mean energy: -15.93612-0.02660j, varE: 5.30649\n",
      "step: 290, loss: 5.57167, mean energy: -17.67925-0.02148j, varE: 2.54001\n",
      "step: 300, loss: 5.73651, mean energy: -18.22958-0.06379j, varE: 2.83022\n",
      "Best model saved at epoch 306 with best E=-18.75902-0.24230j, varE=0.83789\n",
      "Best model saved at epoch 310 with best E=-18.94051+0.06014j, varE=0.62081\n",
      "step: 310, loss: 0.43588, mean energy: -18.94051+0.06014j, varE: 0.62081\n",
      "Best model saved at epoch 312 with best E=-18.99259-0.13114j, varE=0.95508\n",
      "step: 320, loss: -4.10574, mean energy: -18.70051+0.02185j, varE: 1.29203\n",
      "Best model saved at epoch 323 with best E=-19.09674-0.00173j, varE=0.50894\n",
      "step: 330, loss: 1.41754, mean energy: -18.86368-0.02023j, varE: 0.80538\n",
      "Best model saved at epoch 333 with best E=-19.12623-0.06329j, varE=0.77965\n",
      "Best model saved at epoch 334 with best E=-19.15157-0.04886j, varE=0.95459\n",
      "Best model saved at epoch 337 with best E=-19.20319-0.03021j, varE=0.48522\n",
      "step: 340, loss: 0.43542, mean energy: -19.04946+0.00462j, varE: 0.50238\n",
      "Best model saved at epoch 350 with best E=-19.35287-0.06824j, varE=0.47517\n",
      "step: 350, loss: 0.04947, mean energy: -19.35287-0.06824j, varE: 0.47517\n",
      "step: 360, loss: 1.81589, mean energy: -18.84120-0.16869j, varE: 0.69106\n",
      "step: 370, loss: -2.00146, mean energy: -19.10204-0.02783j, varE: 0.59402\n",
      "step: 380, loss: -2.10242, mean energy: -19.28311-0.01756j, varE: 0.40024\n",
      "Best model saved at epoch 388 with best E=-19.38170-0.04563j, varE=0.69727\n",
      "step: 390, loss: 0.34619, mean energy: -19.21540-0.00614j, varE: 0.34723\n",
      "Best model saved at epoch 395 with best E=-19.39612+0.02823j, varE=0.55844\n",
      "Best model saved at epoch 400 with best E=-19.41693-0.03355j, varE=0.55308\n",
      "step: 400, loss: 1.21414, mean energy: -19.41693-0.03355j, varE: 0.55308\n",
      "step: 410, loss: 0.39145, mean energy: -19.35243+0.03864j, varE: 0.27292\n",
      "step: 420, loss: 0.48959, mean energy: -19.27549-0.02694j, varE: 0.24565\n",
      "Best model saved at epoch 425 with best E=-19.44298-0.00900j, varE=0.13652\n",
      "step: 430, loss: 0.14029, mean energy: -19.33130+0.03082j, varE: 0.16030\n",
      "step: 440, loss: 2.69348, mean energy: -19.35630+0.02022j, varE: 0.27313\n",
      "step: 450, loss: 14.89838, mean energy: -20.09156+1.18446j, varE: 96.27929\n",
      "step: 460, loss: -0.05478, mean energy: -19.22833+0.02361j, varE: 0.26945\n",
      "Best model saved at epoch 469 with best E=-19.45232+0.00927j, varE=0.27128\n",
      "step: 470, loss: 1.42810, mean energy: -19.32827-0.06273j, varE: 0.27633\n",
      "step: 480, loss: -0.10065, mean energy: -19.40837-0.01833j, varE: 0.47230\n",
      "Best model saved at epoch 486 with best E=-19.46501+0.00120j, varE=0.25737\n",
      "step: 490, loss: -0.02197, mean energy: -19.40001+0.01339j, varE: 0.15071\n",
      "Best model saved at epoch 497 with best E=-19.49075+0.00955j, varE=0.12333\n",
      "step: 500, loss: 0.10855, mean energy: -19.30998+0.02168j, varE: 0.20880\n",
      "step: 510, loss: 0.14435, mean energy: -19.37185+0.01329j, varE: 0.20280\n",
      "step: 520, loss: -0.44699, mean energy: -19.39057+0.01541j, varE: 0.28961\n",
      "Best model saved at epoch 522 with best E=-19.54850+0.03867j, varE=0.24888\n",
      "step: 530, loss: 1.49274, mean energy: -19.32589+0.01884j, varE: 0.09365\n",
      "step: 540, loss: 0.37463, mean energy: -19.38963-0.04285j, varE: 0.17720\n",
      "step: 550, loss: -0.27856, mean energy: -19.36004+0.00534j, varE: 0.03766\n",
      "Total time taken: 3.794\n"
     ]
    }
   ],
   "source": [
    "nsteps = 551\n",
    "start = time.time()\n",
    "\n",
    "mE, vE = run_J1J2(wf=wf_egru, numsteps=nsteps, systemsize=syssize, var_tol=var_tol, J1_  = J1, \n",
    "                   J2_ = J2, Marshall_sign = True, \n",
    "                  numsamples = nssamples, learningrate = 1e-2, seed = 111, fname = 'results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587abf4",
   "metadata": {},
   "source": [
    "# HypGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966ac94",
   "metadata": {},
   "source": [
    "## units = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 65\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "wf_hgru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87817afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.74295, mean energy: 14.03100-0.32254j, varE: 0.95289\n",
      "Best model saved at epoch 6 with best E=13.73505+0.01051j, varE=0.73169\n",
      "Best model saved at epoch 8 with best E=13.67992+0.06148j, varE=0.74102\n",
      "Best model saved at epoch 9 with best E=13.58967+0.01312j, varE=0.50181\n",
      "Best model saved at epoch 10 with best E=13.47068+0.13275j, varE=0.54319\n",
      "step: 10, loss: -1.68040, mean energy: 13.47068+0.13275j, varE: 0.54319\n",
      "Best model saved at epoch 11 with best E=13.44525-0.08029j, varE=0.56998\n",
      "Best model saved at epoch 12 with best E=13.19057+0.02662j, varE=0.41150\n",
      "Best model saved at epoch 16 with best E=12.90695-0.02321j, varE=0.70844\n",
      "Best model saved at epoch 17 with best E=12.77762+0.05737j, varE=0.76422\n",
      "Best model saved at epoch 18 with best E=12.56496+0.02165j, varE=0.89283\n",
      "step: 20, loss: 1.15945, mean energy: 13.27719-0.04709j, varE: 0.73105\n",
      "step: 30, loss: -0.23508, mean energy: 13.11357-0.16251j, varE: 0.50233\n",
      "Best model saved at epoch 34 with best E=12.56171+0.03610j, varE=0.52422\n",
      "step: 40, loss: 0.27540, mean energy: 12.57699-0.10484j, varE: 1.22388\n",
      "Best model saved at epoch 49 with best E=12.45394-0.00203j, varE=0.97504\n",
      "step: 50, loss: 0.10950, mean energy: 12.53473+0.05144j, varE: 0.78977\n",
      "Best model saved at epoch 55 with best E=12.34059-0.03808j, varE=0.70410\n",
      "step: 60, loss: 0.35106, mean energy: 12.37139+0.02063j, varE: 0.89699\n",
      "Best model saved at epoch 69 with best E=12.25173-0.02696j, varE=0.70286\n",
      "step: 70, loss: -0.86810, mean energy: 12.34061-0.03704j, varE: 1.92736\n",
      "Best model saved at epoch 74 with best E=12.07522-0.02244j, varE=0.52486\n",
      "step: 80, loss: -0.66493, mean energy: 12.10591-0.00893j, varE: 0.56466\n",
      "step: 90, loss: -0.16157, mean energy: 12.25795-0.04595j, varE: 0.50335\n",
      "Best model saved at epoch 100 with best E=12.05101-0.02076j, varE=0.57903\n",
      "step: 100, loss: 0.47161, mean energy: 12.05101-0.02076j, varE: 0.57903\n",
      "step: 110, loss: 0.10939, mean energy: 12.38723-0.02691j, varE: 1.25103\n",
      "Best model saved at epoch 114 with best E=11.87609-0.02389j, varE=0.35586\n",
      "step: 120, loss: -0.50156, mean energy: 12.03673-0.01378j, varE: 0.57376\n",
      "step: 130, loss: 0.01575, mean energy: 12.10993+0.01628j, varE: 0.55240\n",
      "Best model saved at epoch 131 with best E=11.81864+0.06161j, varE=0.71583\n",
      "step: 140, loss: -1.49193, mean energy: 12.23887-0.04209j, varE: 1.90560\n",
      "step: 150, loss: 0.14230, mean energy: 11.97395+0.02468j, varE: 0.43747\n",
      "step: 160, loss: 0.18402, mean energy: 12.22096+0.03552j, varE: 0.51112\n",
      "step: 170, loss: -1.16399, mean energy: 12.25007-0.04532j, varE: 2.64094\n",
      "step: 180, loss: -0.16721, mean energy: 11.84282+0.01289j, varE: 0.29902\n",
      "step: 190, loss: -0.91702, mean energy: 11.85811-0.01771j, varE: 0.33446\n",
      "Best model saved at epoch 193 with best E=11.78777-0.01990j, varE=0.43356\n",
      "step: 200, loss: 0.34369, mean energy: 12.03503-0.01988j, varE: 0.45493\n",
      "step: 210, loss: -1.30865, mean energy: 12.36122-0.04873j, varE: 2.40072\n",
      "Best model saved at epoch 215 with best E=11.76828+0.00273j, varE=0.35230\n",
      "step: 220, loss: 0.01167, mean energy: 11.92876-0.04763j, varE: 0.46062\n",
      "Best model saved at epoch 230 with best E=11.75132+0.05857j, varE=0.74812\n",
      "step: 230, loss: 0.27208, mean energy: 11.75132+0.05857j, varE: 0.74812\n",
      "Best model saved at epoch 240 with best E=11.70861+0.02669j, varE=0.44009\n",
      "step: 240, loss: 0.57312, mean energy: 11.70861+0.02669j, varE: 0.44009\n",
      "step: 250, loss: 0.39799, mean energy: 11.71437+0.03120j, varE: 0.83158\n",
      "Best model saved at epoch 260 with best E=11.68911+0.00273j, varE=0.74227\n",
      "step: 260, loss: 0.85563, mean energy: 11.68911+0.00273j, varE: 0.74227\n",
      "step: 270, loss: -0.93797, mean energy: 12.02799+0.00365j, varE: 0.52560\n",
      "step: 280, loss: -0.29340, mean energy: 12.01909+0.04072j, varE: 0.31439\n",
      "step: 290, loss: 0.11454, mean energy: 11.69448-0.01223j, varE: 0.44207\n",
      "step: 300, loss: -0.27146, mean energy: 11.97045-0.02106j, varE: 0.24345\n",
      "step: 310, loss: 0.29490, mean energy: 11.95896+0.01071j, varE: 0.38093\n",
      "step: 320, loss: -0.13824, mean energy: 11.81795-0.00050j, varE: 0.37354\n",
      "Best model saved at epoch 321 with best E=11.67380+0.01263j, varE=0.33074\n",
      "step: 330, loss: 0.12774, mean energy: 11.80007-0.00131j, varE: 0.29970\n",
      "step: 340, loss: 0.27893, mean energy: 11.72282-0.00168j, varE: 0.43491\n",
      "step: 350, loss: -0.40812, mean energy: 11.86928+0.01255j, varE: 0.57409\n",
      "step: 360, loss: 0.48228, mean energy: 11.84966-0.01503j, varE: 0.39380\n",
      "step: 370, loss: 0.58558, mean energy: 11.89690-0.00359j, varE: 0.36295\n",
      "step: 380, loss: 0.81743, mean energy: 11.84126-0.01514j, varE: 0.32160\n",
      "step: 390, loss: 0.68545, mean energy: 11.84739+0.05690j, varE: 0.43068\n",
      "Best model saved at epoch 393 with best E=11.62734+0.03987j, varE=0.52291\n"
     ]
    }
   ],
   "source": [
    "nsteps=451\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=var_tol,\n",
    "                          J1_ = J1, J2_ = J2, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = 'results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b9fdb",
   "metadata": {},
   "source": [
    "## units = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d7e7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_hyp_wf at 0x7fec10c580d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 75\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "wf_hgru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8615c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -0.92465, mean energy: 12.68636+0.32971j, varE: 3.82003\n",
      "step: 10, loss: 2.85232, mean energy: -1.81129-0.30339j, varE: 12.74316\n",
      "step: 20, loss: -2.29882, mean energy: -1.93857-0.61335j, varE: 10.45107\n",
      "step: 30, loss: -3.43175, mean energy: -7.13363+0.38479j, varE: 11.82614\n",
      "step: 40, loss: -0.03452, mean energy: -10.33448-0.05775j, varE: 9.95715\n",
      "step: 50, loss: 11.12245, mean energy: -12.35862-0.51670j, varE: 12.40858\n",
      "step: 60, loss: -12.87794, mean energy: -13.66236-0.00403j, varE: 7.30138\n",
      "step: 70, loss: 2.24240, mean energy: -15.55847+0.15462j, varE: 4.90676\n",
      "step: 80, loss: 0.88129, mean energy: -15.68585-0.22353j, varE: 5.52227\n",
      "step: 90, loss: 1.19136, mean energy: -17.00282-0.09222j, varE: 1.89293\n",
      "step: 100, loss: -4.10201, mean energy: -17.46417-0.05483j, varE: 1.99029\n",
      "Best model saved at epoch 108 with best E=-17.61498-0.20078j, varE=0.93841\n",
      "step: 110, loss: 0.80226, mean energy: -17.61976+0.07846j, varE: 2.15439\n",
      "step: 120, loss: 2.40427, mean energy: -17.83212+0.28087j, varE: 5.73030\n",
      "step: 130, loss: -4.11000, mean energy: -14.43507-0.08449j, varE: 11.78834\n",
      "step: 140, loss: 13.37685, mean energy: -16.23718+0.01331j, varE: 11.48549\n",
      "step: 150, loss: -4.95563, mean energy: -17.48417-0.13755j, varE: 8.03090\n",
      "step: 160, loss: -1.63568, mean energy: -17.57778-0.10243j, varE: 1.50839\n",
      "Best model saved at epoch 165 with best E=-17.65552-0.25718j, varE=0.95496\n",
      "Best model saved at epoch 168 with best E=-17.69599-0.05463j, varE=0.74704\n",
      "step: 170, loss: 1.62247, mean energy: -17.86674-0.06740j, varE: 1.84879\n",
      "Best model saved at epoch 172 with best E=-17.84647-0.10435j, varE=0.52210\n",
      "Best model saved at epoch 180 with best E=-18.17447-0.11441j, varE=0.84102\n",
      "step: 180, loss: 0.37190, mean energy: -18.17447-0.11441j, varE: 0.84102\n",
      "step: 190, loss: 1.01199, mean energy: -18.23956+0.06031j, varE: 2.06166\n",
      "step: 200, loss: -2.55286, mean energy: -18.40457+0.18265j, varE: 3.52662\n",
      "step: 210, loss: 5.21094, mean energy: -18.50211-0.09438j, varE: 3.31987\n",
      "Best model saved at epoch 219 with best E=-19.23078+0.04372j, varE=0.86382\n",
      "step: 220, loss: 0.00510, mean energy: -19.16271+0.03400j, varE: 2.84768\n",
      "Best model saved at epoch 227 with best E=-19.44376-0.06199j, varE=0.65495\n",
      "Best model saved at epoch 230 with best E=-19.51154-0.01867j, varE=0.89183\n",
      "step: 230, loss: 0.63751, mean energy: -19.51154-0.01867j, varE: 0.89183\n",
      "step: 240, loss: 1.82040, mean energy: -19.26647-0.16624j, varE: 4.57672\n",
      "Best model saved at epoch 241 with best E=-19.54823-0.02711j, varE=0.60751\n",
      "Best model saved at epoch 246 with best E=-19.59968-0.00570j, varE=0.85634\n",
      "Best model saved at epoch 248 with best E=-19.64585+0.03931j, varE=0.44796\n",
      "step: 250, loss: -2.30099, mean energy: -19.52170+0.00852j, varE: 0.66607\n",
      "Best model saved at epoch 254 with best E=-19.66574-0.07445j, varE=0.80152\n",
      "Best model saved at epoch 257 with best E=-19.68680-0.06550j, varE=0.51180\n",
      "step: 260, loss: -1.39569, mean energy: -19.39636+0.12537j, varE: 1.02813\n",
      "Best model saved at epoch 264 with best E=-19.69635-0.05854j, varE=0.67660\n",
      "Best model saved at epoch 269 with best E=-19.70041-0.02851j, varE=0.84700\n",
      "step: 270, loss: 1.15350, mean energy: -19.64755+0.04381j, varE: 1.40741\n",
      "Best model saved at epoch 276 with best E=-19.72464-0.01261j, varE=0.96246\n",
      "step: 280, loss: 0.31778, mean energy: -19.63212+0.07885j, varE: 0.52141\n",
      "Best model saved at epoch 281 with best E=-19.74685-0.00248j, varE=0.20210\n",
      "step: 290, loss: -2.75378, mean energy: -19.66053+0.05597j, varE: 0.47838\n",
      "Best model saved at epoch 291 with best E=-19.75147-0.01977j, varE=0.21877\n",
      "Best model saved at epoch 294 with best E=-19.81863-0.05000j, varE=0.70917\n",
      "step: 300, loss: -0.49780, mean energy: -19.65902+0.03934j, varE: 0.19105\n",
      "step: 310, loss: 0.78806, mean energy: -19.64870+0.10677j, varE: 0.56912\n",
      "Best model saved at epoch 319 with best E=-19.86717-0.03891j, varE=0.65391\n",
      "step: 320, loss: -2.37436, mean energy: -19.71531+0.11578j, varE: 0.78657\n",
      "step: 330, loss: 5.25974, mean energy: -19.59067+0.03977j, varE: 0.53179\n",
      "step: 340, loss: -0.41049, mean energy: -19.51814-0.06721j, varE: 0.75178\n",
      "step: 350, loss: -6.37347, mean energy: -19.51424+0.08809j, varE: 0.90771\n",
      "step: 360, loss: 0.63461, mean energy: -19.79636+0.07792j, varE: 0.27698\n",
      "Best model saved at epoch 369 with best E=-19.91912+0.02344j, varE=0.50833\n",
      "step: 370, loss: 1.33377, mean energy: -19.54699+0.03381j, varE: 1.58615\n",
      "Best model saved at epoch 376 with best E=-19.95980+0.07762j, varE=0.66627\n",
      "step: 380, loss: -1.52481, mean energy: -19.58172+0.02450j, varE: 2.33315\n",
      "Best model saved at epoch 383 with best E=-20.05903+0.17030j, varE=0.71193\n",
      "step: 390, loss: -0.44559, mean energy: -19.85472+0.02243j, varE: 0.28741\n",
      "step: 400, loss: 3.34348, mean energy: -19.85734+0.01872j, varE: 0.21266\n",
      "step: 410, loss: -1.86026, mean energy: -19.85967+0.06847j, varE: 0.51636\n",
      "step: 420, loss: 2.32877, mean energy: -19.89252+0.07075j, varE: 0.81414\n",
      "step: 430, loss: -1.99188, mean energy: -19.77033+0.00345j, varE: 0.53241\n",
      "step: 440, loss: -0.97900, mean energy: -19.85642-0.00110j, varE: 0.21437\n",
      "step: 450, loss: -0.92581, mean energy: -19.88579-0.05192j, varE: 0.20154\n",
      "Total time taken: 20.171\n"
     ]
    }
   ],
   "source": [
    "nsteps=451\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=var_tol,\n",
    "                          J1_ = J1, J2_ = J2, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = 'results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57709c",
   "metadata": {},
   "source": [
    "## units = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b558ca5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<j1j2_hyprnn_wf.rnn_hyp_wf at 0x7fec53683a00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type = 'HypGRU'\n",
    "hidden_units = 70\n",
    "wf_hgru = rnn_hyp_wf(syssize, cell_type, 'hyp', 'id', hidden_units)\n",
    "wf_hgru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d193586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -1.29541, mean energy: 14.04700-0.32995j, varE: 1.03517\n",
      "step: 10, loss: -5.99432, mean energy: -0.54169-0.33113j, varE: 13.23973\n",
      "step: 20, loss: 2.92644, mean energy: -2.78089-0.06543j, varE: 11.98459\n",
      "step: 30, loss: -0.36508, mean energy: -5.90059-0.25664j, varE: 11.90237\n",
      "step: 40, loss: 0.23384, mean energy: -8.42594-0.11747j, varE: 11.67800\n",
      "step: 50, loss: 0.80785, mean energy: -9.16418+0.31293j, varE: 10.42564\n",
      "step: 60, loss: 0.34436, mean energy: -10.54586-0.44947j, varE: 13.69431\n",
      "step: 70, loss: 24.45192, mean energy: -12.43834+0.40538j, varE: 9.50198\n",
      "step: 80, loss: -11.58441, mean energy: -14.30781-0.38888j, varE: 7.93608\n",
      "step: 90, loss: -17.04039, mean energy: -14.73596-0.19473j, varE: 7.05121\n",
      "step: 100, loss: 7.95970, mean energy: -15.75093+0.01986j, varE: 2.92365\n",
      "step: 110, loss: -3.30879, mean energy: -15.54691-0.17175j, varE: 21.35016\n",
      "step: 120, loss: 5.43274, mean energy: -16.28220-0.08301j, varE: 3.23980\n",
      "step: 130, loss: -6.89590, mean energy: -16.96695-0.02077j, varE: 1.49464\n",
      "step: 140, loss: -5.94571, mean energy: -16.93150+0.29755j, varE: 1.59871\n",
      "step: 150, loss: 20.36525, mean energy: -16.92601+0.03203j, varE: 2.62915\n",
      "step: 160, loss: -20.42006, mean energy: -16.45463-0.10899j, varE: 3.56089\n",
      "step: 170, loss: 15.20018, mean energy: -16.59532-0.21399j, varE: 3.13657\n",
      "Best model saved at epoch 179 with best E=-17.16995-0.02925j, varE=0.93203\n",
      "step: 180, loss: -12.96971, mean energy: -17.11624+0.08468j, varE: 1.96920\n",
      "Best model saved at epoch 187 with best E=-17.27944-0.04542j, varE=0.95096\n",
      "step: 190, loss: -6.54562, mean energy: -17.24435-0.02247j, varE: 1.17215\n",
      "Best model saved at epoch 193 with best E=-17.37873-0.09850j, varE=0.99176\n",
      "step: 200, loss: -7.30656, mean energy: -17.28990-0.20759j, varE: 1.02025\n",
      "step: 210, loss: 5.28496, mean energy: -17.27367-0.19098j, varE: 1.32066\n",
      "Best model saved at epoch 215 with best E=-17.51044+0.11019j, varE=0.93083\n",
      "step: 220, loss: 2.71915, mean energy: -17.10293+0.09029j, varE: 1.27606\n",
      "step: 230, loss: -10.20239, mean energy: -17.11592-0.00164j, varE: 1.72805\n",
      "step: 240, loss: 1.60902, mean energy: -17.27540-0.01051j, varE: 1.80324\n",
      "Best model saved at epoch 243 with best E=-17.65987+0.05233j, varE=0.98481\n",
      "step: 250, loss: -1.23730, mean energy: -17.30847-0.06986j, varE: 1.27841\n",
      "step: 260, loss: 26.35524, mean energy: -17.10299-0.04393j, varE: 1.82718\n",
      "step: 270, loss: -6.78033, mean energy: -17.53695-0.22794j, varE: 0.97855\n",
      "step: 280, loss: 2.10219, mean energy: -17.64324+0.04915j, varE: 0.44314\n",
      "Best model saved at epoch 287 with best E=-17.74851+0.12695j, varE=0.33379\n",
      "step: 290, loss: -0.28047, mean energy: -17.11223+0.02986j, varE: 2.30433\n",
      "step: 300, loss: -2.99226, mean energy: -16.81694-0.10515j, varE: 3.34066\n",
      "step: 310, loss: 2.49928, mean energy: -16.70885-0.09773j, varE: 3.43202\n",
      "step: 320, loss: 3.29236, mean energy: -17.15305-0.01406j, varE: 1.44802\n",
      "step: 330, loss: -6.72501, mean energy: -17.44921-0.12601j, varE: 1.36371\n",
      "step: 340, loss: 4.15004, mean energy: -17.05319+0.16259j, varE: 3.15608\n",
      "step: 350, loss: 13.90257, mean energy: -16.81514+0.19442j, varE: 3.57020\n",
      "step: 360, loss: 8.72667, mean energy: -17.18317+0.11378j, varE: 3.39731\n",
      "step: 370, loss: -3.12354, mean energy: -17.48770-0.10035j, varE: 1.53918\n",
      "step: 380, loss: -5.85776, mean energy: -17.26045-0.05868j, varE: 0.91545\n",
      "step: 390, loss: 7.54315, mean energy: -17.38382+0.04591j, varE: 1.16401\n",
      "step: 400, loss: -8.36032, mean energy: -17.47892+0.16916j, varE: 1.08836\n",
      "Best model saved at epoch 405 with best E=-17.78317+0.02994j, varE=0.98162\n",
      "step: 410, loss: -2.83409, mean energy: -17.54740+0.21038j, varE: 1.64841\n",
      "step: 420, loss: 5.68315, mean energy: -17.72634+0.03514j, varE: 0.48401\n",
      "Best model saved at epoch 421 with best E=-17.79551-0.03813j, varE=0.26098\n",
      "step: 430, loss: -11.14430, mean energy: -17.59991-0.11025j, varE: 0.68398\n",
      "step: 440, loss: 9.10873, mean energy: -17.70859+0.01516j, varE: 0.51729\n",
      "step: 450, loss: -5.81364, mean energy: -17.63743+0.03662j, varE: 0.61768\n",
      "Best model saved at epoch 454 with best E=-17.87147+0.02982j, varE=0.58287\n",
      "step: 460, loss: -1.81621, mean energy: -17.62389+0.02722j, varE: 1.13868\n",
      "Best model saved at epoch 467 with best E=-17.90087-0.01843j, varE=0.32998\n",
      "step: 470, loss: -5.33353, mean energy: -17.63676-0.02147j, varE: 0.93963\n",
      "step: 480, loss: -2.41444, mean energy: -17.60138+0.01075j, varE: 0.85578\n",
      "Best model saved at epoch 485 with best E=-17.90403+0.01978j, varE=0.64584\n",
      "step: 490, loss: 1.45111, mean energy: -17.76982+0.04621j, varE: 0.29442\n",
      "step: 500, loss: -3.35352, mean energy: -17.56879-0.07734j, varE: 0.98285\n",
      "step: 510, loss: 0.75838, mean energy: -17.74667+0.02429j, varE: 0.34794\n",
      "step: 520, loss: 3.34000, mean energy: -17.93243-0.07050j, varE: 1.20727\n",
      "step: 530, loss: -0.44640, mean energy: -17.66751+0.09341j, varE: 0.78478\n",
      "step: 540, loss: 8.27338, mean energy: -17.77484+0.01094j, varE: 0.35580\n",
      "step: 550, loss: -0.31503, mean energy: -17.68554-0.05521j, varE: 0.55485\n",
      "Total time taken: 22.258\n"
     ]
    }
   ],
   "source": [
    "nsteps=551\n",
    "start = time.time()\n",
    "mE, vE = run_J1J2_hypvars(wf=wf_hgru, numsteps=nsteps, systemsize=syssize, var_tol=var_tol,\n",
    "                          J1_ = J1, J2_ = J2, Marshall_sign = True, \n",
    "                           numsamples = nssamples,  lr1=1e-2, lr2=1e-2, seed = 111, fname = 'results')\n",
    "finish = time.time()\n",
    "duration = finish-start\n",
    "print(f'Total time taken: {np.round(duration/3600,3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

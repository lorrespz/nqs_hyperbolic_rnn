{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb653aa-63e9-4bc7-8f2f-5f753a1d9a45",
   "metadata": {},
   "source": [
    "# 2d TFIM, Nx=9, Ny=9: RNN wavefunction\n",
    "\n",
    "This notebook is part of the work arXiv:2505.22083 (https://arxiv.org/abs/2505.22083), \"Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz\". Code written by HLD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7affa059-8897-4797-b886-67902add0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6cd7bf-cb6d-4618-9631-4dc5c6f8313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utility')\n",
    "nx=9\n",
    "ny=9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998e0c0-ed3e-4b9f-94fa-1d76d97260f7",
   "metadata": {},
   "source": [
    "# 2D Euclidean RNN wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5781392d-ea79-4fe0-b22c-79f532a9bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 01:13:21.221406: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 99.52610, mean energy: -171.50757, varE: 1192.98716\n",
      "step: 10, loss: 4.32659, mean energy: -251.64474, varE: 51.90247\n",
      "step: 20, loss: 1.42653, mean energy: -253.17176, varE: 34.05232\n",
      "step: 30, loss: -0.55779, mean energy: -254.83670, varE: 14.73283\n",
      "step: 40, loss: 2.53220, mean energy: -253.73725, varE: 6.35569\n",
      "step: 50, loss: -2.31830, mean energy: -255.21420, varE: 7.38155\n",
      "step: 60, loss: -0.24763, mean energy: -255.88676, varE: 6.49972\n",
      "step: 70, loss: 1.66018, mean energy: -255.27775, varE: 4.10465\n",
      "step: 80, loss: -3.14718, mean energy: -256.52777, varE: 5.70188\n",
      "step: 90, loss: 0.90258, mean energy: -255.95475, varE: 3.23064\n",
      "step: 100, loss: 0.93752, mean energy: -255.95968, varE: 3.85492\n",
      "step: 110, loss: -0.32775, mean energy: -256.46397, varE: 2.64548\n",
      "Best model saved at epoch 112 with best E=-255.97246, varE=1.68652\n",
      "Best model saved at epoch 115 with best E=-256.47110, varE=1.85032\n",
      "Best model saved at epoch 120 with best E=-256.52772, varE=1.94036\n",
      "step: 120, loss: 0.35864, mean energy: -256.52772, varE: 1.94036\n",
      "step: 130, loss: 0.23281, mean energy: -255.80973, varE: 2.26350\n",
      "Best model saved at epoch 135 with best E=-256.68280, varE=1.39842\n",
      "step: 140, loss: 2.30543, mean energy: -255.95237, varE: 2.72506\n",
      "step: 150, loss: -0.06260, mean energy: -256.25118, varE: 2.00584\n",
      "step: 160, loss: -0.28309, mean energy: -256.53459, varE: 1.33924\n",
      "step: 170, loss: 0.32848, mean energy: -256.15203, varE: 1.17555\n",
      "Best model saved at epoch 172 with best E=-256.73494, varE=1.79129\n",
      "step: 180, loss: -0.97298, mean energy: -256.51778, varE: 1.29523\n",
      "step: 190, loss: 1.14060, mean energy: -256.42121, varE: 1.79236\n",
      "step: 200, loss: -0.29374, mean energy: -256.42034, varE: 1.16064\n",
      "step: 210, loss: -0.70086, mean energy: -256.59642, varE: 1.37723\n",
      "step: 220, loss: -0.10795, mean energy: -256.56046, varE: 0.87637\n",
      "step: 230, loss: -0.53446, mean energy: -256.51627, varE: 1.45406\n",
      "step: 240, loss: -0.61989, mean energy: -256.47551, varE: 1.41882\n",
      "step: 250, loss: -0.30974, mean energy: -256.43047, varE: 1.18130\n",
      "step: 260, loss: 0.43798, mean energy: -256.23497, varE: 1.19818\n",
      "step: 270, loss: -0.28516, mean energy: -256.31591, varE: 0.91310\n",
      "step: 280, loss: -0.45726, mean energy: -255.93032, varE: 0.87176\n",
      "step: 290, loss: -0.23924, mean energy: -256.68523, varE: 1.03318\n",
      "step: 300, loss: 0.05821, mean energy: -256.38153, varE: 1.20362\n",
      "step: 310, loss: 1.09650, mean energy: -256.23011, varE: 1.53257\n",
      "step: 320, loss: 0.47807, mean energy: -256.42731, varE: 1.07138\n",
      "step: 330, loss: -0.57172, mean energy: -256.34538, varE: 0.98868\n",
      "Best model saved at epoch 332 with best E=-256.76662, varE=1.38260\n",
      "step: 340, loss: 0.11984, mean energy: -256.62096, varE: 1.08232\n",
      "step: 350, loss: -0.29365, mean energy: -256.46880, varE: 1.42515\n",
      "Training took 3.519 hours\n"
     ]
    }
   ],
   "source": [
    "from tfim2d_2drnn_train_loop import run_2DTFIM\n",
    "#DMRG results: -256.55347963709767\n",
    "t0 = time.time()\n",
    "RNNEnergy, varRNNEnergy = run_2DTFIM(numsteps = 351, Nx = nx, Ny = ny,\n",
    "                                     Bx = 3, num_units = 50, numsamples = 50, \n",
    "                                     learningrate = 1e-2, var_tol = 2.0, seed = 111)\n",
    "t1 = time.time()\n",
    "print(f'Training took {np.round((t1-t0)/3600,3)} hours')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

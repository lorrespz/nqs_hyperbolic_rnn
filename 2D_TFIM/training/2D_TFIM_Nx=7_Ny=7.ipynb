{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb653aa-63e9-4bc7-8f2f-5f753a1d9a45",
   "metadata": {},
   "source": [
    "# 2d TFIM, Nx=7, Ny=7: RNN wavefunction\n",
    "\n",
    "This notebook is part of the work arXiv:2505.22083 (https://arxiv.org/abs/2505.22083), \"Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz\". Code written by HLD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7affa059-8897-4797-b886-67902add0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6cd7bf-cb6d-4618-9631-4dc5c6f8313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../utility')\n",
    "nx=7\n",
    "ny=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d87ce-9c95-41c8-8434-35b7bef0ab01",
   "metadata": {},
   "source": [
    "# 1D Euclidean RNN wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d199a7af-a3fe-4c87-9cb1-0f8d6827ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 22:51:49.486045: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tfim2d_1drnn_train_loop import run_2DTFIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd046c10-c2b8-4533-b3a8-c1e9b89f46b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: -0.41688, mean energy: -148.04443, varE: 53.72432\n",
      "step: 10, loss: -1.95816, mean energy: -152.67705, varE: 53.68035\n",
      "step: 20, loss: -3.72762, mean energy: -152.89466, varE: 33.38950\n",
      "step: 30, loss: 0.49056, mean energy: -151.54717, varE: 31.62673\n",
      "step: 40, loss: 0.34163, mean energy: -153.14966, varE: 25.55991\n",
      "step: 50, loss: -1.87028, mean energy: -152.38435, varE: 21.24630\n",
      "step: 60, loss: -2.48529, mean energy: -151.54939, varE: 20.13270\n",
      "step: 70, loss: 0.69137, mean energy: -153.03743, varE: 22.54859\n",
      "step: 80, loss: -0.36827, mean energy: -152.76147, varE: 30.59277\n",
      "step: 90, loss: 3.49571, mean energy: -152.34164, varE: 12.23650\n",
      "step: 100, loss: -2.74314, mean energy: -152.58074, varE: 38.89730\n",
      "step: 110, loss: 1.73032, mean energy: -154.09262, varE: 23.77851\n",
      "step: 120, loss: 1.01057, mean energy: -153.30663, varE: 30.74433\n",
      "step: 130, loss: -0.03769, mean energy: -153.30637, varE: 23.57516\n",
      "step: 140, loss: 0.70454, mean energy: -153.03776, varE: 29.98616\n",
      "step: 150, loss: -2.22078, mean energy: -152.08302, varE: 27.42214\n",
      "step: 160, loss: 0.10555, mean energy: -152.86344, varE: 24.33863\n",
      "step: 170, loss: -1.52589, mean energy: -153.70802, varE: 17.32709\n",
      "step: 180, loss: -2.48560, mean energy: -152.40887, varE: 22.70654\n",
      "step: 190, loss: 0.82696, mean energy: -154.82809, varE: 23.10845\n",
      "step: 200, loss: 2.37346, mean energy: -153.65337, varE: 29.65198\n",
      "step: 210, loss: 0.97700, mean energy: -153.31999, varE: 19.15026\n",
      "step: 220, loss: -0.38300, mean energy: -153.85052, varE: 16.05269\n",
      "step: 230, loss: 1.85062, mean energy: -152.38907, varE: 16.90182\n",
      "step: 240, loss: -1.12109, mean energy: -153.50589, varE: 15.53623\n",
      "step: 250, loss: -0.18358, mean energy: -152.57062, varE: 21.07796\n",
      "step: 260, loss: -0.38033, mean energy: -152.23293, varE: 14.16556\n",
      "step: 270, loss: 1.68539, mean energy: -153.80722, varE: 16.23201\n",
      "step: 280, loss: 1.14109, mean energy: -154.30212, varE: 17.53345\n",
      "step: 290, loss: -0.43466, mean energy: -153.48639, varE: 13.67837\n",
      "step: 300, loss: 1.50289, mean energy: -153.09814, varE: 15.59655\n",
      "step: 310, loss: 0.60203, mean energy: -153.83255, varE: 18.04380\n",
      "Best model saved at epoch 314 with best E=-154.35165, varE=8.55981\n",
      "step: 320, loss: 0.04488, mean energy: -152.76215, varE: 11.95604\n",
      "Best model saved at epoch 329 with best E=-154.41907, varE=9.03735\n",
      "step: 330, loss: -0.16582, mean energy: -152.92641, varE: 7.76377\n",
      "step: 340, loss: 1.94581, mean energy: -154.85055, varE: 15.18522\n",
      "step: 350, loss: -0.28219, mean energy: -154.13917, varE: 10.35229\n",
      "step: 360, loss: -0.73367, mean energy: -153.54714, varE: 11.93891\n",
      "step: 370, loss: -0.66508, mean energy: -153.39831, varE: 10.40840\n",
      "step: 380, loss: -0.31958, mean energy: -153.32289, varE: 14.82969\n",
      "step: 390, loss: 1.11042, mean energy: -153.44320, varE: 16.25311\n",
      "step: 400, loss: 1.20276, mean energy: -154.01854, varE: 18.72071\n",
      "step: 410, loss: 0.00472, mean energy: -153.13597, varE: 14.24220\n",
      "step: 420, loss: -0.62279, mean energy: -153.99988, varE: 11.51754\n",
      "step: 430, loss: -0.39695, mean energy: -153.39179, varE: 13.90495\n",
      "step: 440, loss: -0.23647, mean energy: -153.61580, varE: 14.85733\n",
      "step: 450, loss: 1.81040, mean energy: -153.80082, varE: 16.54056\n",
      "Training took 1.375 hours\n"
     ]
    }
   ],
   "source": [
    "#DMRG results: -154.8463098708262\n",
    "t0 = time.time()\n",
    "RNNEnergy, varRNNEnergy = run_2DTFIM(numsteps = 451, Nx = nx, Ny = ny,\n",
    "                                     Bx = 3, cell = 'EuclGRU', num_units = 50, numsamples = 50, \n",
    "                                     learningrate = 1e-2, var_tol=10.0, seed = 111)\n",
    "t1 = time.time()\n",
    "print(f'Training took {np.round((t1-t0)/3600,3)} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb291d-b23c-4daf-82c3-6e1e6f852f73",
   "metadata": {},
   "source": [
    "# 1D hyperbolic GRU wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2abed6cf-cc47-40c3-bb56-f6fca9d01d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfim2d_1drnn_train_loop import run_2DTFIM_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a6aa1c-8419-447b-b0ed-03db6fb269e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.46552, mean energy: -145.14385, varE: 40.52758\n",
      "step: 10, loss: 1.31462, mean energy: -152.07515, varE: 57.64350\n",
      "step: 20, loss: 0.05859, mean energy: -153.04909, varE: 34.11836\n",
      "step: 30, loss: -0.11393, mean energy: -151.97035, varE: 24.88795\n",
      "step: 40, loss: -1.55449, mean energy: -152.94238, varE: 24.55308\n",
      "step: 50, loss: -1.62556, mean energy: -152.53050, varE: 18.04969\n",
      "step: 60, loss: 2.61208, mean energy: -152.20856, varE: 22.90590\n",
      "step: 70, loss: -0.49377, mean energy: -154.34938, varE: 14.13663\n",
      "step: 80, loss: 2.24186, mean energy: -153.08958, varE: 25.02256\n",
      "step: 90, loss: 0.34017, mean energy: -153.87197, varE: 21.59351\n",
      "step: 100, loss: -1.89269, mean energy: -153.43994, varE: 32.25742\n",
      "step: 110, loss: 0.33005, mean energy: -154.44711, varE: 14.90765\n",
      "step: 120, loss: 0.04426, mean energy: -154.30017, varE: 22.66788\n",
      "step: 130, loss: -0.68220, mean energy: -154.01475, varE: 15.04852\n",
      "step: 140, loss: 1.77456, mean energy: -153.37290, varE: 17.50017\n",
      "step: 150, loss: -1.19885, mean energy: -153.19490, varE: 14.78180\n",
      "step: 160, loss: -0.09873, mean energy: -153.91118, varE: 14.61466\n",
      "step: 170, loss: -0.08861, mean energy: -154.50586, varE: 12.43765\n",
      "step: 180, loss: -1.30867, mean energy: -154.34656, varE: 11.25590\n",
      "step: 190, loss: 2.99099, mean energy: -154.44359, varE: 12.92322\n",
      "step: 200, loss: -0.83267, mean energy: -153.94896, varE: 9.46921\n",
      "step: 210, loss: 2.34296, mean energy: -154.48746, varE: 9.17418\n",
      "step: 220, loss: 0.73927, mean energy: -155.23344, varE: 7.98271\n",
      "step: 230, loss: 0.97521, mean energy: -153.62823, varE: 8.45672\n",
      "step: 240, loss: 0.18055, mean energy: -153.70963, varE: 8.66809\n",
      "Best model saved at epoch 244 with best E=-154.07327, varE=4.50604\n",
      "step: 250, loss: 0.04558, mean energy: -152.74890, varE: 8.08621\n",
      "step: 260, loss: -1.51949, mean energy: -154.45765, varE: 7.58743\n",
      "step: 270, loss: 2.07037, mean energy: -154.09218, varE: 9.41989\n",
      "step: 280, loss: -0.34593, mean energy: -154.17951, varE: 8.56864\n",
      "step: 290, loss: -0.10190, mean energy: -154.12550, varE: 6.19061\n",
      "step: 300, loss: 0.73333, mean energy: -153.72865, varE: 10.31322\n",
      "step: 310, loss: 0.87464, mean energy: -154.12928, varE: 9.86343\n",
      "step: 320, loss: 1.47689, mean energy: -154.34747, varE: 6.82144\n",
      "step: 330, loss: -1.30143, mean energy: -153.73752, varE: 6.18455\n",
      "Best model saved at epoch 340 with best E=-154.45850, varE=4.77157\n",
      "step: 340, loss: 0.10723, mean energy: -154.45850, varE: 4.77157\n",
      "step: 350, loss: -0.59983, mean energy: -154.74346, varE: 6.79519\n",
      "Best model saved at epoch 351 with best E=-154.67769, varE=4.75704\n",
      "step: 360, loss: -1.43061, mean energy: -153.27378, varE: 6.85487\n",
      "step: 370, loss: 0.09161, mean energy: -153.98104, varE: 7.75101\n",
      "step: 380, loss: 0.17463, mean energy: -153.83088, varE: 10.00561\n",
      "step: 390, loss: 2.08037, mean energy: -153.41961, varE: 6.38727\n",
      "step: 400, loss: -1.48530, mean energy: -154.04898, varE: 8.80780\n",
      "step: 410, loss: 0.55008, mean energy: -154.08887, varE: 10.73651\n",
      "step: 420, loss: -1.43996, mean energy: -154.44574, varE: 7.24921\n",
      "step: 430, loss: -1.11943, mean energy: -153.89260, varE: 6.62130\n",
      "step: 440, loss: -0.36994, mean energy: -154.12444, varE: 7.93257\n",
      "step: 450, loss: -0.29138, mean energy: -154.45830, varE: 5.80551\n",
      "Training took 13.937 hours\n"
     ]
    }
   ],
   "source": [
    "#DMRG results:-154.8463098708262\n",
    "t0 = time.time()\n",
    "RNNEnergy, varRNNEnergy = run_2DTFIM_hyp(numsteps = 451, Nx = nx, Ny = ny,\n",
    "                                     Bx = 3, cell = 'HypGRU', num_units = 50, numsamples = 50, \n",
    "                                    lr1=1e-2, lr2 =1e-2, var_tol =5.0, seed = 111)\n",
    "t1 = time.time()\n",
    "print(f'Training took {np.round((t1-t0)/3600,3)} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998e0c0-ed3e-4b9f-94fa-1d76d97260f7",
   "metadata": {},
   "source": [
    "# 2D Euclidean RNN wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781392d-ea79-4fe0-b22c-79f532a9bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 67.99718, mean energy: -118.83154, varE: 619.74469\n",
      "step: 10, loss: 7.80871, mean energy: -146.86717, varE: 66.09517\n",
      "step: 20, loss: 1.56779, mean energy: -152.46680, varE: 11.61670\n",
      "step: 30, loss: 2.50961, mean energy: -153.00206, varE: 12.91329\n",
      "step: 40, loss: 0.20455, mean energy: -153.97759, varE: 4.06755\n",
      "step: 50, loss: -0.11351, mean energy: -154.43426, varE: 3.06121\n",
      "step: 60, loss: -0.47626, mean energy: -154.49792, varE: 2.90568\n",
      "step: 70, loss: -0.30767, mean energy: -154.33715, varE: 1.48207\n",
      "step: 80, loss: 0.48618, mean energy: -154.43150, varE: 1.66261\n",
      "step: 90, loss: -0.69889, mean energy: -153.93844, varE: 3.28588\n",
      "step: 100, loss: 0.11298, mean energy: -154.65414, varE: 2.09021\n",
      "step: 110, loss: -0.14445, mean energy: -154.64973, varE: 1.75673\n",
      "step: 120, loss: 0.00269, mean energy: -154.78722, varE: 1.18527\n",
      "step: 130, loss: 0.41644, mean energy: -154.80240, varE: 1.07686\n",
      "step: 140, loss: -0.10571, mean energy: -154.78261, varE: 0.79553\n",
      "step: 150, loss: -0.36091, mean energy: -154.73933, varE: 0.72591\n",
      "step: 160, loss: 0.22057, mean energy: -154.86053, varE: 0.73451\n",
      "step: 170, loss: 0.08405, mean energy: -154.91333, varE: 0.98945\n",
      "step: 180, loss: 0.00499, mean energy: -154.74904, varE: 0.53098\n",
      "step: 190, loss: 0.94536, mean energy: -154.41583, varE: 0.74549\n",
      "step: 200, loss: 0.21644, mean energy: -154.86921, varE: 0.53935\n",
      "step: 210, loss: -0.67098, mean energy: -154.74755, varE: 0.77025\n",
      "step: 220, loss: 0.03019, mean energy: -154.72687, varE: 0.92891\n",
      "step: 230, loss: 0.51422, mean energy: -154.60380, varE: 1.25509\n",
      "step: 240, loss: 0.77253, mean energy: -154.62756, varE: 0.41516\n",
      "step: 250, loss: -0.43557, mean energy: -154.80111, varE: 0.60134\n",
      "step: 260, loss: 0.43245, mean energy: -154.72626, varE: 0.72202\n",
      "step: 270, loss: 0.42654, mean energy: -154.56040, varE: 0.87789\n",
      "step: 280, loss: -0.06777, mean energy: -154.83602, varE: 0.63402\n",
      "Best model saved at epoch 286 with best E=-154.70017, varE=0.24205\n",
      "step: 290, loss: -0.07015, mean energy: -154.89863, varE: 0.42593\n",
      "step: 300, loss: 0.16012, mean energy: -154.73475, varE: 0.44086\n",
      "step: 310, loss: 0.20774, mean energy: -154.70694, varE: 0.60349\n",
      "step: 320, loss: 0.00586, mean energy: -154.85260, varE: 0.46916\n"
     ]
    }
   ],
   "source": [
    "from tfim2d_2drnn_train_loop import run_2DTFIM\n",
    "#DMRG results:  -154.8463098708262\n",
    "t0 = time.time()\n",
    "RNNEnergy, varRNNEnergy = run_2DTFIM(numsteps = 351, Nx = nx, Ny = ny,\n",
    "                                     Bx = 3, num_units = 50, numsamples = 50, \n",
    "                                     learningrate = 1e-2, var_tol = 0.25, seed = 111)\n",
    "t1 = time.time()\n",
    "print(f'Training took {np.round((t1-t0)/3600,3)} hours')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

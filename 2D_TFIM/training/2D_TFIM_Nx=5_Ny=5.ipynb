{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb653aa-63e9-4bc7-8f2f-5f753a1d9a45",
   "metadata": {},
   "source": [
    "# 2d TFIM, Nx=5, Ny=5: RNN wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7affa059-8897-4797-b886-67902add0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6cd7bf-cb6d-4618-9631-4dc5c6f8313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utility')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d87ce-9c95-41c8-8434-35b7bef0ab01",
   "metadata": {},
   "source": [
    "# 1D Euclidean RNN wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d199a7af-a3fe-4c87-9cb1-0f8d6827ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 01:50:50.188462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tfim2d_1drnn_train_loop import run_2DTFIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edfaeea-ae9e-4cee-b90f-1be7e8898a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.07853, mean energy: -75.06439, varE: 32.99193\n",
      "step: 10, loss: -0.47176, mean energy: -76.30537, varE: 16.66408\n",
      "step: 20, loss: -0.08230, mean energy: -77.09531, varE: 13.65355\n",
      "step: 30, loss: 1.03129, mean energy: -77.98813, varE: 11.68439\n",
      "step: 40, loss: -0.23361, mean energy: -78.08533, varE: 7.69525\n",
      "step: 50, loss: 1.37316, mean energy: -77.74352, varE: 13.14361\n",
      "step: 60, loss: -2.03308, mean energy: -77.26828, varE: 8.85773\n",
      "step: 70, loss: 1.05318, mean energy: -78.22259, varE: 9.28122\n",
      "step: 80, loss: -0.29649, mean energy: -78.36219, varE: 8.13736\n",
      "step: 90, loss: 1.23303, mean energy: -78.15062, varE: 6.19770\n",
      "step: 100, loss: 0.65376, mean energy: -77.64789, varE: 8.16633\n",
      "step: 110, loss: -0.52550, mean energy: -77.54811, varE: 15.77061\n",
      "step: 120, loss: -1.24336, mean energy: -77.78928, varE: 8.88779\n",
      "step: 130, loss: 0.57743, mean energy: -78.34277, varE: 9.54089\n",
      "step: 140, loss: -0.46790, mean energy: -78.24546, varE: 6.44918\n",
      "step: 150, loss: 0.53900, mean energy: -78.88473, varE: 4.70710\n",
      "step: 160, loss: -0.25892, mean energy: -78.12276, varE: 8.17487\n",
      "step: 170, loss: -0.94501, mean energy: -78.22560, varE: 9.16005\n",
      "step: 180, loss: 0.72428, mean energy: -77.97538, varE: 8.05391\n",
      "step: 190, loss: -1.12685, mean energy: -78.16733, varE: 11.08188\n",
      "step: 200, loss: 0.48400, mean energy: -78.40004, varE: 9.72209\n",
      "step: 210, loss: 0.50025, mean energy: -78.76116, varE: 8.31558\n",
      "step: 220, loss: 0.12844, mean energy: -78.56595, varE: 7.41323\n",
      "step: 230, loss: 1.05116, mean energy: -77.46899, varE: 6.40303\n",
      "step: 240, loss: -0.04597, mean energy: -78.17729, varE: 3.67917\n",
      "step: 250, loss: 0.16977, mean energy: -78.77112, varE: 5.54572\n",
      "step: 260, loss: 0.44948, mean energy: -78.42006, varE: 4.26678\n",
      "step: 270, loss: -0.53229, mean energy: -78.15389, varE: 4.40925\n",
      "step: 280, loss: -0.00827, mean energy: -77.97222, varE: 3.88821\n",
      "step: 290, loss: 0.47619, mean energy: -78.55377, varE: 2.68899\n",
      "step: 300, loss: 0.32985, mean energy: -78.17951, varE: 3.63851\n",
      "step: 310, loss: -1.02276, mean energy: -77.75410, varE: 4.96257\n",
      "step: 320, loss: 0.07300, mean energy: -78.55103, varE: 4.47757\n",
      "step: 330, loss: 0.47663, mean energy: -78.01677, varE: 3.40362\n",
      "step: 340, loss: 0.70985, mean energy: -78.16890, varE: 3.42852\n",
      "step: 350, loss: 0.03508, mean energy: -78.33376, varE: 3.29023\n",
      "step: 360, loss: -0.36429, mean energy: -78.69858, varE: 3.75009\n",
      "step: 370, loss: 1.05767, mean energy: -78.04609, varE: 4.65601\n",
      "Best model saved at epoch 373 with best E=-78.24742, varE=1.72502\n",
      "step: 380, loss: -0.08843, mean energy: -77.87720, varE: 2.93814\n",
      "step: 390, loss: -0.19135, mean energy: -78.52203, varE: 3.75193\n",
      "step: 400, loss: 0.57269, mean energy: -78.48326, varE: 4.17171\n",
      "Training took 0.401 hours\n"
     ]
    }
   ],
   "source": [
    "#DMRG results: -78.68567684975109\n",
    "t0 = time.time()\n",
    "RNNEnergy, varRNNEnergy = run_2DTFIM(numsteps = 401, Nx = 5, Ny = 5,\n",
    "                                     Bx = 3, cell = 'EuclGRU', num_units = 50, numsamples = 50, \n",
    "                                     learningrate = 1e-2, var_tol =2.0, seed = 111)\n",
    "t1 = time.time()\n",
    "print(f'Training took {np.round((t1-t0)/3600,3)} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb291d-b23c-4daf-82c3-6e1e6f852f73",
   "metadata": {},
   "source": [
    "# 1D hyperbolic GRU wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2abed6cf-cc47-40c3-bb56-f6fca9d01d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfim2d_1drnn_train_loop import run_2DTFIM_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb5fb41-4bb6-4dc0-89a8-d4f6a0eb784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.33394, mean energy: -72.39497, varE: 37.65052\n",
      "step: 10, loss: -0.03039, mean energy: -77.33224, varE: 10.11171\n",
      "step: 20, loss: -0.62205, mean energy: -77.93308, varE: 7.91872\n",
      "step: 30, loss: 0.42459, mean energy: -79.02925, varE: 8.50034\n",
      "step: 40, loss: 0.96153, mean energy: -78.64824, varE: 4.26263\n",
      "step: 50, loss: -0.43111, mean energy: -78.51769, varE: 4.63110\n",
      "step: 60, loss: -0.66073, mean energy: -77.77734, varE: 3.94008\n",
      "step: 70, loss: 0.45535, mean energy: -78.35114, varE: 5.03994\n",
      "step: 80, loss: -0.23613, mean energy: -78.39264, varE: 4.54971\n",
      "step: 90, loss: 0.18149, mean energy: -78.20941, varE: 5.20626\n",
      "step: 100, loss: 0.29442, mean energy: -78.22152, varE: 3.54925\n",
      "step: 110, loss: -0.45842, mean energy: -78.06776, varE: 6.21018\n",
      "step: 120, loss: -0.47405, mean energy: -78.14595, varE: 5.26387\n",
      "step: 130, loss: 0.30892, mean energy: -78.54810, varE: 3.69352\n",
      "step: 140, loss: 0.55901, mean energy: -78.16766, varE: 4.14942\n",
      "step: 150, loss: 0.36909, mean energy: -79.22769, varE: 3.23798\n",
      "step: 160, loss: -0.09335, mean energy: -78.29274, varE: 3.76611\n",
      "step: 170, loss: -0.31245, mean energy: -78.67645, varE: 3.84464\n",
      "step: 180, loss: -0.46235, mean energy: -77.99279, varE: 5.74950\n",
      "step: 190, loss: -0.70423, mean energy: -78.53577, varE: 4.49926\n",
      "step: 200, loss: 0.30005, mean energy: -78.22711, varE: 6.36497\n",
      "step: 210, loss: -0.46073, mean energy: -78.45560, varE: 3.93829\n",
      "step: 220, loss: 0.61187, mean energy: -78.11427, varE: 5.28056\n",
      "step: 230, loss: 0.33436, mean energy: -77.78328, varE: 4.91527\n",
      "step: 240, loss: 0.54799, mean energy: -78.77009, varE: 2.56027\n",
      "step: 250, loss: 0.19182, mean energy: -78.98016, varE: 3.45714\n",
      "step: 260, loss: -0.09450, mean energy: -78.15610, varE: 2.76577\n",
      "step: 270, loss: -0.24770, mean energy: -78.61923, varE: 3.78535\n",
      "step: 280, loss: -0.17539, mean energy: -77.64135, varE: 3.24526\n",
      "step: 290, loss: 0.12410, mean energy: -78.50893, varE: 3.11781\n",
      "step: 300, loss: 0.33008, mean energy: -78.49803, varE: 3.38565\n",
      "Best model saved at epoch 309 with best E=-78.70074, varE=1.90471\n",
      "step: 310, loss: -0.12178, mean energy: -77.71466, varE: 4.08870\n",
      "step: 320, loss: -0.19296, mean energy: -78.35426, varE: 4.04288\n",
      "step: 330, loss: 1.18569, mean energy: -77.99841, varE: 4.70925\n",
      "step: 340, loss: 0.35541, mean energy: -78.30274, varE: 3.24690\n",
      "step: 350, loss: 0.18901, mean energy: -78.36168, varE: 4.17510\n",
      "step: 360, loss: 0.22874, mean energy: -78.75818, varE: 4.31280\n",
      "step: 370, loss: 0.30237, mean energy: -78.08008, varE: 4.29253\n",
      "step: 380, loss: 0.55924, mean energy: -78.16878, varE: 3.68145\n",
      "step: 390, loss: -0.28477, mean energy: -78.60241, varE: 2.63142\n",
      "step: 400, loss: 0.08428, mean energy: -78.76206, varE: 3.11338\n",
      "Training took 5.232 hours\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "RNNEnergy, varRNNEnergy = run_2DTFIM_hyp(numsteps = 401, Nx = 5, Ny = 5,\n",
    "                                     Bx = 3, cell = 'HypGRU', num_units = 50, numsamples = 50, \n",
    "                                    lr1=1e-2, lr2 =1e-2, var_tol =2.0, seed = 111)\n",
    "t1 = time.time()\n",
    "print(f'Training took {np.round((t1-t0)/3600,3)} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998e0c0-ed3e-4b9f-94fa-1d76d97260f7",
   "metadata": {},
   "source": [
    "# 2D Euclidean RNN wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5781392d-ea79-4fe0-b22c-79f532a9bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 16.14190, mean energy: -69.53691, varE: 139.12433\n",
      "step: 10, loss: 2.53469, mean energy: -75.48199, varE: 8.17768\n",
      "step: 20, loss: -0.99579, mean energy: -78.18289, varE: 3.13159\n",
      "step: 30, loss: 1.30827, mean energy: -78.67049, varE: 3.56597\n",
      "step: 40, loss: -0.72746, mean energy: -78.45268, varE: 2.04666\n",
      "step: 50, loss: 0.69959, mean energy: -78.30381, varE: 0.99646\n",
      "step: 60, loss: 0.25740, mean energy: -78.66046, varE: 1.00571\n",
      "step: 70, loss: 0.49184, mean energy: -78.54421, varE: 0.91997\n",
      "step: 80, loss: -0.06566, mean energy: -78.74603, varE: 0.50024\n",
      "step: 90, loss: -0.07538, mean energy: -78.67616, varE: 0.55610\n",
      "step: 100, loss: 0.01203, mean energy: -78.54291, varE: 0.29260\n",
      "step: 110, loss: 0.22567, mean energy: -78.68342, varE: 0.40743\n",
      "Best model saved at epoch 118 with best E=-78.71769, varE=0.23791\n",
      "step: 120, loss: 0.15731, mean energy: -78.67516, varE: 0.39717\n",
      "Best model saved at epoch 125 with best E=-78.77050, varE=0.23950\n",
      "step: 130, loss: 0.04965, mean energy: -78.68870, varE: 0.27524\n",
      "step: 140, loss: 0.02342, mean energy: -78.55346, varE: 0.27969\n",
      "step: 150, loss: -0.21853, mean energy: -78.61876, varE: 0.25675\n",
      "step: 160, loss: -0.12351, mean energy: -78.69456, varE: 0.37098\n",
      "Best model saved at epoch 170 with best E=-78.77737, varE=0.19433\n",
      "step: 170, loss: 0.10956, mean energy: -78.77737, varE: 0.19433\n",
      "step: 180, loss: 0.07594, mean energy: -78.72101, varE: 0.24244\n",
      "step: 190, loss: 0.17830, mean energy: -78.58514, varE: 0.32752\n",
      "step: 200, loss: 0.12366, mean energy: -78.59436, varE: 0.36795\n",
      "Training took 0.182 hours\n"
     ]
    }
   ],
   "source": [
    "from tfim2d_2drnn_train_loop import run_2DTFIM\n",
    "#DMRG results: -78.68567684975109\n",
    "t0 = time.time()\n",
    "RNNEnergy, varRNNEnergy = run_2DTFIM(numsteps = 201, Nx = 5, Ny = 5,\n",
    "                                     Bx = 3, num_units = 50, numsamples = 50, \n",
    "                                     learningrate = 1e-2, var_tol = 0.25, seed = 111)\n",
    "t1 = time.time()\n",
    "print(f'Training took {np.round((t1-t0)/3600,3)} hours')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
